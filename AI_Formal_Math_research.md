# **Применение искусственного интеллекта в формальной математике и доказательстве теорем**

Формальная математика – это направление, где математические утверждения и доказательства записываются на формальных языках, позволяющих их **полностью проверить с помощью компьютера**. Ещё в 1950-х годах появились первые попытки автоматического доказательства теорем на компьютерах. Однако лишь в последние годы, благодаря прорывам в области искусственного интеллекта (особенно *machine learning* и больших языковых моделей, LLM), интерес к применению ИИ в формальной математике резко вырос. Число научных работ на стыке глубинного обучения и доказательства теорем увеличилось с буквально нескольких в 2016 году до десятков в 2023-м, и исследования в этой области активно развиваются по многим направлениям.

Главная цель использования ИИ в математике – **помочь преодолеть сложность современных доказательств**. Многие важные теоремы имеют чрезвычайно громоздкие доказательства, где не исключены человеческие ошибки. Формальная проверка шаг за шагом гарантирует, что доказательство корректно, но процесс формализации и поиска доказательства часто требует огромных усилий. Здесь на помощь приходят ИИ-системы, которые могут автоматизировать рутинные шаги, проверять корректность и даже **предлагать новые идеи**. Уже есть примеры, когда нейросети помогли открыть *новые математические результаты*, незамеченные ранее людьми. В данном обзоре рассмотрены основные области, где ИИ применяется в формальной математике и доказательстве теорем, современные системы-доказчики (Lean, Coq, Isabelle, HOL Light и др.), а также последние достижения (особенно 2023–2025 годов) – от проектов Google DeepMind (AlphaTensor, AlphaCode, FunSearch, AlphaProof и др.) до инициатив OpenAI и академических групп (MIT, Stanford, Эдинбург и др.). В завершение представлена сводная таблица ключевых проектов с их задачами и ссылками на оригинальные статьи и репозитории.

## **Основные направления применения ИИ**

### **Автоматическое доказательство теорем** 

Одна из классических задач – *полностью автоматическое* нахождение доказательства заданного формального утверждения. Ещё с 1960-х созданы алгоритмические доказчики (например, системы резолюций для первой порядка логики, такие как **E-Prover** и **Vampire**). Современные ИИ-методы улучшают эти инструменты, применяя обучение для выбора нужных аксиом и шагов. Например, в среде Isabelle механизм *Sledgehammer* интегрирует внешние автоматические доказчики (E, Vampire и др.) и использует машинное обучение для выбора релевантных фактов (*рэфилер MaSh*). В последнее десятилетие появились *нейросетевые доказчики*: системы на основе нейронных сетей генерируют шаги доказательства и ищут доказательство через обучение. Так, модель OpenAI *GPT-f* впервые применяла трансформеры для генерации тактических шагов доказательства, а последующие работы комбинировали языковые модели с *поиском по дереву* или *подкреплением* для повышения эффективности. В 2023 году достигнут заметный прогресс: например, система **AlphaProof** от DeepMind с помощью методов подкрепления научилась решать задачи международной математической олимпиады на уровне призёра – без участия человека находя формальные доказательства сложных задач.

### **Формализация математики** 

Другая сфера – перевод обычной (неформальной) математики в строгую формальную форму. Здесь ИИ призван помочь математикам в трудоёмком процессе записи существующих теорем и доказательств на языке формальных систем. Задача автоформализации пока далека от решённой: например, перевести произвольную страницу учебника или статьи в код Lean или Coq крайне сложно. Однако начаты перспективные исследования. Одни подходы пытаются использовать LLM, обученные на математических текстах и примерах формальных доказательств, чтобы генерировать формулы и доказательства по описанию на естественном языке. Другие работы предлагают разбивать задачу на этапы: сначала распознать структуру доказательства, затем подобрать в библиотеке формальные аналоги утверждений, и наконец сгенерировать проверяемый код доказательства. Уже появились прототипы, способные автоматически формализовать простые задачи – например, перевести школьную олимпиадную задачу в формальное утверждение и доказать её с небольшой корректировкой человека. Ожидается, что в ближайшие годы автоформализация будет стремительно развиваться, учитывая успехи больших языковых моделей в понимании математического текста.

### **Верификация доказательств** 

Одно из основных преимуществ формальной математики машинная проверка корректности. В традиционной ("бумажной") математике даже опубликованные доказательства иногда содержат ошибки или пробелы. Формальная проверка устраняет человеческий фактор: специальное программное ядро (kernel) подтверждает каждое преобразование. ИИ здесь скорее вспомогательная масштабируемость и удобство проверки. Например, при формализации громоздких доказательств (таких как классификация простых групп или доказательство гипотезы Кеплера) можно использовать автоматические тактики и доказатели для проверки рутинных шагов. Такие инструменты, как **CoqHammer** для Coq, способны сами доказать часть тривиальных лем, переводя их в задачу для внешних автоматических решателей и возвращая проверенные решения. Верификация доказательств с помощью ИИ означает также использование машинного обучения для обнаружения потенциальных ошибок или недостающих частей: например, анализ непротиворечивости больших теорий или альтернативная проверка результатов с помощью разных систем (двойная верификация). В итоге, сочетание формальных методов и ИИ обеспечивает беспрецедентный уровень доверия к математическим результатам – любое утверждение, прошедшее формальную проверку, считается доказанным с абсолютной строгостью.

### **Коллаборация человека и ИИ**

На практике наибольших успехов достигает тандем "математик + ИИ", где компьютерные системы помогают, но не заменяют человека. Такие системы называются интерактивными доказателями (proof assistants) – они позволяют пользователю вводить рассуждения на понятном языке, а затем автоматически проверяют и дополняют детали. Современные proof assistant'ы (Lean, Coq, Isabelle и др.) уже включают много встроенной автоматизации, а с помощью ИИ их возможности расширяются ещё больше. Примером успешной коллаборации стала работа DeepMind с университетскими математиками: нейросети были обучены на данных о узлах (объектах в топологии) и подсказали неожиданную гипотезу о связи между их геометрией и алгебраическим инвариантом (подписью узла), которую затем люди доказали традиционными методами. По отзыву специалистов, это первый значимый математический результат, полученный с участием машинного обучения. В других случаях ИИ выполняет роль генератора идей: например, система FunSearch генерирует новые конструкции (программы), которые могут привести к открытию решения открытой задачи, а человек уже анализирует и формализует это решение. В среде формальных доказательств ИИ помогает в поиске подходящих подсказок следующего шага, автодополнения кода доказательства, поиска подходящих ранее доказанных лем. В сообществе Lean уже используются большие языковые модели: они помогают находить нужные утверждения в библиотеке mathlib или даже автоматически заполнять пропущенные фрагменты доказательства. Таким образом, ИИ становится своего рода *"соавтором"* при доказательстве: рутинная проверка и перебор вариантов делегируется машине, тогда как интуиция и общий план остаются за человеком. Многие эксперты считают, что именно в тесном сотрудничестве человека и ИИ кроется путь к решению самых трудных проблем – машина обеспечивает надёжность и скорость, а человек – глубину понимания и творческий вклад.

## **Обзор систем формальной математики**

Чтобы понять, как ИИ применяется в доказательстве теорем, важно познакомиться с ключевыми системами формальной математики – программными комплексами, в которых ведётся формализация и проверка доказательств. Ниже рассмотрены наиболее популярные системы: **Lean**, **Coq**, **Isabelle/HOL** и **HOL Light**. Каждая из них имеет сообщество пользователей, обширную библиотеку формализованных знаний и уже послужила платформой для внедрения ИИ-инструментов.

#### **Lean (Lean 4 и mathlib)**

Lean – сравнительно *молодой* интерактивный доказатель, разработка которого началась Леонардо де Мурой в Microsoft Research в 2013 году. Lean сочетает в себе функциональный язык программирования и средство для написания формальных доказательств, опираясь на строгую теоретико-типовую основу (вариант *Calculus of Constructions*). Особенностью Lean является сильная ориентация на **саморасширяемость**: пользователи могут определять собственные тактики, нотации и автоматические процедуры на самом языке Lean. Это позволило сообществу создать обширную математическую библиотеку **mathlib** – единый репозиторий формализованной математики. Проект mathlib стартовал в 2017 году с целью формализовать как можно больше разделов чистой математики. К 2023 году библиотека mathlib была **портирована на Lean 4** (новую версию системы) и выросла до *свыше 1,5 млн строк* кода доказательств, содержащего более 210 000 теорем и 100 000 определений. Lean 4, официально выпущенный в сентябре 2023 года, значительно повысил производительность и гибкость системы – теперь сам доказатель на 90% написан на языке Lean, что позволяет быстро развивать его возможности. Lean завоевал популярность среди математиков: в нём формализованы современные достижения (например, эксперимент Шольца по формализации теории жидких тензоров) и ведутся активные исследования по интеграции ИИ. В 2023 году вышла работа **LeanDojo** – открытая платформа для обучения языковых моделей на корпусе Lean, включающая данные из mathlib и инструментарий для автоматического доказательства теорем в Lean. LeanDojo предоставляет датасет из ~98 734 теорем и доказательств Lean с разметкой ~130 000 вспомогательных фактов, а также реализует *LLM-провер ReProver* с механизмом вытягивания релевантных лем из огромной библиотеки mathlib. Благодаря этому Lean становится одной из основных площадок для экспериментов по обучению ИИ-доказчиков.

#### **Coq**

Coq – один из *старейших и наиболее развитых* proof assistant'ов, разрабатываемый с 1980-х годов во французском INRIA. Coq основан на мощной теории типов (Calculus of Inductive Constructions) и предоставляет строго формализованный язык для записи математических определений, утверждений и доказательств. Coq прославился тем, что на нём были формализованы ключевые результаты: теорема о четырех красках, громоздкая теорема Фейта–Томпсона о простых группах (полная формализация заняла несколько лет), а также разработаны основы новой теории гомотопических типов (HoTT). Coq активно применяется и в информатике – для верификации программ и оборудования (яркий пример – компилятор CompCert, формально доказанный правильным). С точки зрения ИИ, Coq имеет богатые средства автоматизации: язык тактик Ltac, решатели уравнений, арифметические процедуры и т.д. Для подключения внешних ИИ-решателей создан **CoqHammer** – "молот" (hammer) интеграции с автоматическими доказателями. CoqHammer может автоматически попытаться доказать текущую цель в Coq, используя базу известных лем и внешние системы первого порядка, а затем вернуть доказательство, проверенное Coq-ядром. В последние годы появились и нейросетевые надстройки: например, проект *CoqGym* собирает данные о шагах доказательств в Coq для обучения моделей, а исследователи экспериментируют с LLM, генерирующими тактики Coq на естественном языке. Таким образом, Coq остаётся флагманским инструментом формальной проверки, соединяя десятилетия накопленного опыта в автоматизации с новыми подходами машинного обучения.

#### Isabelle/HOL

Isabelle – универсальная платформа для формальных доказательств, разработанная Л. Полсоном и коллегами (начиная с 1986 г.). Isabelle примечательна тем, что является generic proof assistant: в ней реализован метаязык и небольшой логический kernel, на базе которого можно определять различные формальные логики (т. н. object logics). Наиболее популярным является вариант Isabelle/**HOL** — интерактивный доказатель для классической высшей логики (Higher-Order Logic). Isabelle/HOL широко используется и обладает огромным архивом формальных доказательств (Isabelle AFP), где собраны тысячи формализованных теорем из разных областей математики и компьютерных наук. С практической стороны Isabelle славится мощной встроенной автоматизацией. Помимо традиционных средств (перебора, переписывания и т.д.), Isabelle включает интерфейс Sledgehammer, который по запросу пользователя пытается автоматически доказать текущую цель, обращаясь к внешним решателям — как классическим (SMT-солвер CVC4, автоматы первого порядка E, SPASS, Vampire), так и специализированным методам внутри Isabelle. Sledgehammer сам отбирает подходящие факты из контекста (используя в том числе и машинное обучение, например компонент MaSh), отправляет задачу внешнему доказателю и затем реконструирует найденное решение в средстве Isabelle (через инструмент Metis). Этот *полуавтоматический* режим значительно ускоряет работу, позволяя пользователю доверять рутинные шаги ИИ-инструменту. Сообщество Isabelle также активно исследует применение нейросетей – от отбора фактов до предложения тактик. Например, разрабатываются графовые нейросети для предсказания полезных лем, улучшенные версии hammer-инструментов с учётом эмбеддингов и т.д. Благодаря открытой архитектуре Isabelle, новые ИИ-модули можно встраивать, не нарушая надёжности проверки (ядро Isabelle остаётся минимальным и проверяет каждый шаг). Isabelle/HOL вместе с Coq и Lean формирует основу современного ландшафта, и все три системы являются целевыми для различных ИИ-инициатив.

#### **HOL Light**

**HOL Light** – облегчённая система для классической высшей логики, созданная Джоном Харрисоном в 1990-х как упрощение более раннего HOL. HOL Light написана на OCaml и характеризуется экстремально малым ядром и простыми принципами построения теорий. Несмотря на кажущуюся минималистичность, HOL Light продемонстрировала способность формализовывать очень сложные результаты. Сам Харрисон с её помощью формализовал основную теорему анализа (о существовании и единственности решений уравнений), теорему Дирихле о простых числах в арифметических прогрессиях, а совместно с Т. Хейлзом – проверил доказательство гипотезы Кеплера (проект Flyspeck). HOL Light стала и полигоном для исследований ИИ: на её базе Google DeepMind создал обучающую среду **HOList**, представляющую из себя набор из ~30 тысяч теорем и доказательств в формате, удобном для reinforcement learning-алгоритмов. В рамках HOList были опробованы подходы с глубоким обучением для автоматического доказательства, и получены первые успехи: нейросети научились доказывать значительную долю задач из библиотеки HOL Light. Вдобавок, существовал датасет **HolStep** (2017) для обучения тактик HOL по логам доказательств. Хотя HOL Light сейчас используется реже, идеи, опробованные на ней, переносятся на другие системы. Её ценят за прозрачность: каждый вывод легко проследить до аксиом через цепочку простых правил. Для ИИ это удобная площадка – минимизировать сложность логики и фокусироваться на поиске доказательства. В перспективе, наработки HOList и других проектов на HOL Light могут интегрироваться в более мощные системы вроде Isabelle и Lean.

(Помимо указанных, существуют и другие системы: например, Mizar – один из первых доказателей (1970-е), вдохновивший многие последующие проекты, а также Metamath – экстремально простой формализм, использованный в экспериментах OpenAI GPT-f. Однако основные тенденции сегодня связаны с развитием Lean, Coq, Isabelle и HOL.)

## Последние достижения и научные публикации (2023–2025)

В период 2023–2025 гг. в сфере ИИ-доказательства теорем произошёл качественный скачок. Появились **прорывные работы**, показавшие, что современные модели способны решать ранее не поддающиеся автоматизации математические задачи. Ниже мы рассмотрим ключевые достижения этого периода, распределённые по ведущим исследовательским группам и проектам.

**Google DeepMind:** Эта компания (ныне подразделение Google) явно стала лидером по применению ИИ в математике. В 2022-2023 гг. DeepMind представила несколько знаковых систем. Во-первых, **AlphaTensor** – первая ИИ-система, сумевшая *открыть новый алгоритм* для фундаментальной задачи умножения матриц. AlphaTensor формулирует поиск алгоритма как игру для агента (на основе архитектуры AlphaZero) и с помощью обучения с подкреплением обнаружила способ перемножать матрицы 4×5 и 5×5 за 76 умножений вместо 80 – быстрее, чем лучшие человеческие разработки. Это решает давнюю открытую проблему оптимизации матричного умножения. Более того, AlphaTensor нашёл целое *семейство новых алгоритмов*, некоторые из которых на 10–20% эффективнее при реализации на современных процессорах и GPU. Во-вторых, **AlphaCode** — модель для генерации исходного кода, нацеленная на задачи спортивного программирования. В опубликованной работе (Science, 2022) показано, что AlphaCode достиг уровня среднего участника соревнований Codeforces, успешно решая ~30% сложных алгоритмических задач. Это означает, что ИИ научился понимать условие, разрабатывать и кодировать алгоритм решения – по сути, приближаясь к навыкам соревнующихся программистов. AlphaCode добивается этого сочетанием большой обученной модели и обширного поиска решений с последующей верификацией результатов.

В 2023 году DeepMind совершила ещё один шаг: в журнале Nature был представлен метод **FunSearch**, предназначенный для **автоматического открытия математических результатов** с помощью LLM. FunSearch (от function search) сочетает крупную языковую модель (для генерации идей в виде программного кода) и специального оценщика, который отсеивает некорректные решения, предотвращая «галлюцинации» нейросети. В процессе итеративного эволюционного поиска система генерирует и улучшает набор программ-кандидатов. Применив FunSearch, авторам удалось впервые с помощью ИИ решить открытые математические задачи: в частности, найти новые решения знаменитой задачи Cap Set (о максимальном множестве без трёхточечной арифметической прогрессии). Также система сама вывела улучшенные алгоритмы для NP-трудной задачи упаковки бинарных объектов (bin packing). Эти результаты получили широкий резонанс: фактически, ИИ начал самостоятельно делать вклад в математику, предлагая полностью проверяемые (поскольку представлены в виде кода) открытия. Важное преимущество FunSearch – выходные данные представлены в воспроизводимой форме (программа), что облегчает проверку и понимание человеком.

Последним громким успехом DeepMind стала связка **AlphaProof** и **AlphaGeometry**. В июле 2024 г. объявлено, что их объединённая система решила *4 из 6 задач* Международной математической олимпиады 2024, набрав 28 баллов из 42 – уровень **серебряной медали** IMO. AlphaProof – это новая RL-модель, тренированная для формального доказательства задач в популярных системах (возможно Lean или Isabelle), а AlphaGeometry 2 – усовершенствованный модуль для геометрических задач. Стоит отметить, что *формулировку задач Олимпиады в формальном виде выполняли люди* (эксперты перевели текст задач в формальные цели), однако все дальнейшие шаги – поиск решения и запись полного доказательства – система выполнила сама. Особенно впечатляет, что AlphaProof справилась с самой трудной алгебраической задачей IMO-2024, которую решили лишь 5 участников-людей. Решения ИИ были проверены официальными судьями (включая лауреата Филдсовской премии Т. Гауэрса) и получили максимально возможные баллы. Это достижение приближает реализацию так называемого **IMO Grand Challenge** – задачи, поставленной сообществом, создать ИИ, способный завоевать золото на Международной олимпиаде по математике в формате «формулировка-доказательство» (F2F). Теперь серебро уже взято, и цель золота (решить хотя бы 5 из 6 задач) становится обозримой перспективой.

В 2023 г. был представлен **LeanDojo**, о котором упоминалось выше. LeanDojo знаменует важную веху: это полноценный набор инструментов и данных для исследования ИИ-доказателей на базе Lean. Он устраняет барьеры воспроизводимости предыдущих работ, предлагая открытые датасеты, обученные модели и интеграцию с Lean. В частности, модель ReProver из LeanDojo реализует подход retrieval-augmented (доказательство с подсказками из базы): при каждом шаге она с помощью специального retriever'а выбирает из mathlib нужные леммы, благодаря чему на сложных теоремах превосходит даже GPT-4. LeanDojo уже вдохновил последующие исследования – например, работы по улучшению выбора предпосылок с помощью графовых нейросетей и новые бенчмарки для Lean.

**OpenAI:** Компания OpenAI одной из первых еще в 2020 г. продемонстрировала потенциал больших языковых моделей для доказательства теорем. Их система **GPT-f** (2020) использовала модифицированную GPT-3 для генерации шагов доказательства в системе Metamath. При помощи обучения на корпусе формальных доказательств GPT-f научилась автоматически доказывать простые утверждения, предсказывая какую следующую тактику или правило применения нужно использовать. Хотя процент решённых задач тогда был скромным, эта работа показала принципиальную возможность «научить» трансформер логическим рассуждениям. В 2022 г. команда (частично связанная с OpenAI) опубликовала бенчмарк **miniF2F**, уже упоминавшийся выше. MiniF2F предоставляет 488 формализованных задач олимпиадного уровня на трёх системах (Lean, Isabelle, Metamath) и служит открытым тестом для сравнения разных ИИ-доказчиков. На нём проверялись как GPT-f, так и другие подходы, стимулируя прогресс (к 2023 г. лучшие модели решают ~30–40% задач из miniF2F). OpenAI продолжает исследования: в 2023 появились работы по *curriculum* learning (постепенному обучению моделей на все более сложных формальных задачах) и эксперименты с GPT-4, способным в интерактивном режиме помогать пользователю формализовывать доказательство. Хотя у OpenAI нет отдельного «Alpha»-проекта, сопоставимого с DeepMind, их общие достижения в LLM (ChatGPT/GPT-4) оказывают большое влияние и на эту сферу. Уже есть энтузиасты, использующие ChatGPT для помощи при доказательствах в Lean: модель предлагает следующий шаг или находит подходящую лемму из документации. Можно ожидать, что будущие версии GPT будут ещё лучше понимать формальные языки и синтезировать доказательства, особенно если их обучить на данных из Coq/Lean.

**Академические группы:** Университеты и исследовательские институты по всему миру активно вовлечены в эту тематику. В 2023 г. прошли специальные семинары и воркшопы по ИИ в математических изысканиях (например, мероприятие Национальной академии наук США) — в их материалах отмечено, что ИИ способен ускорить открытия, выявляя скрытые структуры в массивах математических данных. Группы в МІТ, Стэнфорде, Оксфорде, Эдинбурге, Праге и др. занимаются как теорией (например, исследования по автоформализации на базе лингвистики), так и практикой (создание бенчмарков, улучшение алгоритмов поиска доказательств). Так, университет Эдинбурга исторически связан с темой автоматического доказательства (там работал создатель первой системы ЛЦД-решателя Робин Милнер), и нынешние учёные вносят вклад, работая над обучаемыми решателями для Isabelle/HOL. В Стэнфорде и Беркли ведутся работы по нейронному выбору лемм и по объединению символьных методов с нейросетями (гибридные доказчики). В 2023 опубликован обширный **обзор по deep learning для theorem proving**, обобщающий более 170 работ – он также подготовлен силами академического консорциума (Торонто, Калтех и др.). Все эти инициативы, вместе взятые, формируют интенсивно растущее поле исследований. Ниже приведена таблица, суммирующая основные проекты последних лет, их цели и ссылки на исходные статьи или код.

#### Ключевые проекты 2022-2025

| Проект | Описание и достижения | Источник |
|--------|----------------------|----------|
| **AlphaTensor** (DeepMind, 2022) | Первая система для автоматического открытия новых алгоритмов. AlphaTensor открыл более эффективные способы умножения матриц, решив 50-летнюю проблему (например, 4×4 матрицы за 47 умножений). Нашёл сотни алгоритмов с рекордной сложностью и оптимизировал их под разное железо. | [Nature 2022](https://www.nature.com/articles/s41586-022-05172-4); [GitHub](https://github.com/deepmind/alphatensor) |
| **AlphaCode** (DeepMind, 2022) | Модель генерации кода, достигшая уровня среднего человека в соревнованиях по программированию. Решала сложные алгоритмические задачи на Codeforces, заняв место около топ-54% участников. Генерирует множество решений и автоматически фильтрует по успешному выполнению тестов. | [Science 2022](https://www.science.org/doi/10.1126/science.abq1158); [arXiv](https://arxiv.org/abs/2203.07814) |
| **FunSearch** (DeepMind, 2023) | Метод эволюционного поиска программ с использованием LLM. Сгенерировал новые математические открытия: нашёл решения комбинаторной задачи Cap Set и улучшенные алгоритмы для bin-packing. Первая демонстрация, что LLM может привести к решению открытого математического вопроса. | [Nature 2023](https://www.nature.com/articles/s41586-023-06924-6); [GitHub](https://github.com/google-deepmind/funsearch) |
| **LeanDojo** (2023) | Открытая платформа для исследований ИИ-доказательства на Lean. Включает инструменты выгрузки датасетов из библиотеки mathlib (≈98k теорем, 130k лемм), обученные модели и бенчмарки. Реализует доказчик ReProver с механизмом выбора релевантных фактов из большой библиотеки. Свободно доступен (MIT License). | [NeurIPS 2023](https://arxiv.org/abs/2306.15626); [Сайт LeanDojo](https://leandojo.org/) |
| **AlphaProof** (DeepMind, 2024) | Система на основе RL и нейросетей для формального доказательства сложных задач. Вместе с AlphaGeometry 2 решила 4/6 задач IMO 2024, набрав серебро. AlphaProof генерирует полноценные формальные доказательства в интерактивной системе, справляясь даже с задачами, непосильными большинству участников Олимпиады. | [DeepMind Blog](https://deepmind.google/blog/ai-solves-imo-problems-at-silver-medal-level/); [Nature 2025](https://www.nature.com/articles/s41586-025-09833-y) |
| **GPT-f / miniF2F** (OpenAI, 2020–22) | GPT-f – первый трансформер, обученный доказывать формальные теоремы (Metamath). Предсказывал следующий шаг доказательства, генерируя тактики на основе состояния цели. miniF2F – межсистемный набор задач (488 теорем) для оценки нейродоказчиков на Lean, Isabelle и др. Стал стандартным тестом в исследованиях. | [arXiv GPT-f](https://arxiv.org/abs/2009.03393); [GitHub miniF2F](https://github.com/openai/miniF2F) |

### **Выводы и перспективы**

Применение ИИ в формальной математике из стадии экспериментов стремительно переходит к стадии реальных результатов. Уже сегодня **нейросети способны решать математические задачи соревновательного уровня**, генерировать новые алгоритмы и помогать в проверке грандиозных доказательств. Ключевым достижением можно считать демонстрацию того, что ИИ может действовать *на пределе современных знаний*: например, AlphaProof фактически выступил на Олимпиаде за несколько дней и занял место рядом с сильнейшими молодыми математиками мира. При этом, человек остаётся неотъемлемой частью процесса – формулируя задачи, направляя поиск, интерпретируя открытия. Вероятно, такой симбиоз сохранится и в будущем: ИИ станет мощным «ускорителем» исследований, освобождая время для творческих инсайтов.

Важный показатель прогресса – **рост сообщества и инфраструктуры**. Появление открытых библиотек (mathlib, AFP Isabelle и др.) и платформ вроде LeanDojo делает входной барьер для исследований ниже, привлекает новых специалистов. Выпуск обзоров и проведение международных семинаров говорит о формировании *междисциплинарного поля* на стыке математики, ИИ и компьютерных наук. Большие игроки (Big Tech и топ-университеты) инвестируют ресурсы, видя перспективы автоматизации математического труда.

Что ждет впереди в 2025–2030 годах? Эксперты прогнозируют прорывы в **автоформализации** – возможно, ИИ-системы научатся переводить текст учебника или черновика математической статьи в проверяемый код, устраняя главную «узкость» процесса. Мы вероятно увидим первое **полностью автоматическое доказательство** новой нетривиальной теоремы, выполненное связкой нейросети и формального доказчика без подсказок человека. Цель завоевать золото на IMO или решить задачу из списка проблем тысячелетия может перестать быть фантастикой. В то же время, появятся и **новые вызовы**: как проверить не только корректность, но и значимость открытого ИИ результата? как сделать так, чтобы машинные доказательства были понятны людям? Эти вопросы потребуют сотрудничества математиков и специалистов по ИИ.

Можно с уверенностью сказать, что **ИИ не заменит математика, но изменит стиль его работы**. Рутинная проверка и поиск будут автоматизированы, тогда как человеческая интуиция сфокусируется на постановке проблем и интерпретации решений. Подобно тому, как вычислительные средства расширили возможности науки в XX веке, интеллектуальные системы расширят границы познания в XXI. Формальная математика, долго считавшаяся нишевой, благодаря ИИ может стать повсеместным стандартом обоснования результатов – от чистой теории до прикладных областей. Перспектива весьма вдохновляющая: возможно, уже вскоре мы станем свидетелями того, как человек и искусственный интеллект вместе докажут теорему, которую по отдельности ни один из них доказать не мог.

---

# **Искусственный интеллект в формальной математике: обзор работ за 2025 год**

## **Автоматическое доказательство теорем и достижения на соревнованиях**

- **AlphaProof и AlphaGeometry (DeepMind)** — связка формальных доказчиков на основе RL, которая в 2024 году впервые достигла уровня серебряной медали на Международной математической олимпиаде (IMO). Система AlphaProof (для алгебры/комбинаторики/теории чисел) обучалась методом AlphaZero на миллионах формализованных задач, а AlphaGeometry решала задачи геометрии; вместе они решили 4 из 6 задач IMO 2024, включая самую сложную, набрав 28 баллов (уровень серебра). Это был прорыв: ИИ впервые продемонстрировал способность соревноваться с лучшими школьниками в формальном формате.

- **Gemini с режимом Deep Think (Google DeepMind)** — в 2025 году новый большой языковой модели Gemini преодолел достижения AlphaProof. Благодаря усовершенствованному режиму многовариантного рассуждения *Deep Think* и обучению с усилением на математических задачах, Gemini решила 5 из 6 задач IMO 2025 и набрала 35 баллов, что соответствует уровню золотой медали. В отличие от прошлогоднего подхода, Gemini работала **end-to-end** на естественном языке: она напрямую генерировала строго проверяемые решения из текстов задач (без ручной формализации) и уложилась в отведённые 4,5 часа соревнования. Организаторы IMO подтвердили, что решения были корректны и понятны, тем самым впервые ИИ достиг *«золотого»* уровня в решении олимпиадных задач.

- **Kimina-Prover** — экспериментальный крупный формальный доказчик (модель 72B), обученный с помощью **RL** от модели Qwen 2.5. В работе *"Kimina-Prover Preview"* (апрель 2025) представлено, что эта модель осваивает «формальный стиль рассуждений», эмулирующий человеческую стратегию: поэтапно строит доказательство, получая обратную связь от проверяющего ядра Lean. Kimina-Prover установила новый рекорд на бенчмарке MiniF2F – **80.7%** решённых теорем (при большом лимите выборок). Важно, что модель показывает высокую эффективность даже при минимальном числе попыток (pass@1) благодаря RL-подходу и масштабируется с ростом размера. Авторы открыли упрощённые версии Kimina (1.5B и 7B параметров) для сообщества.

- **DeepSeek-Prover-V2** — открытый формальный **LLM-доказчик** для Lean4, представленный командой DeepSeek (Ren et al., 2025). Модель огромного размера (оценочно ~671 млрд параметров) обучена с нуля на основе стратегии *декомпозиции целей*: более мощный модуль DeepSeek-V3 рекурсивно разбивает сложные задачи на подзадачи и генерирует черновые доказательства, которые затем используются для RL-тюнинга финального провера. В результате DeepSeek-Prover-V2 достиг **88.9%** успеха на тестовом наборе MiniF2F и решил 49 из 658 задач PutnamBench – это один из лучших показателей среди нейросетевых доказчиков. Кроме того, авторы представили новый набор задач **ProverBench** (325 формализованных задач, включая 15 недавних задач AIME) для расширенной оценки. Модель DeepSeek-Prover-V2 в открытом доступе сокращает разрыв между неформальным решателем (DeepSeek-V3) и формальным – на 15 задачах AIME она решила 6, в то время как мощный неформальный GPT-решатель решил 8, что свидетельствует о сближении возможностей.

- **LeanAbell-Prover-V2** — относительно компактная модель-доказчик (7 млрд параметров) от исследователей из Tencent (Ji et al., 2025), демонстрирующая интеграцию верификатора в процесс вывода. Используя Reinforcement Learning с обратной связью от ядра Lean4, модель динамически узнаёт о правильности своих шагов: при ошибке компиляции она получает сигнал и учится корректировать ход доказательства. Такой self-aware подход позволил улучшить точность вывода: LeanAbell-Prover-V2 превзошёл базовые модели аналогичного размера на ~2–3% (pass@128) на MiniF2F, например, дал +3.2% к результату distilled-7В версии Kimina и +2.0% к DeepSeek-7В. Код, данные и сами модели LeanAbell v2 опубликованы в открытом доступе, что способствует воспроизводимости.

- **Gödel-Prover** и **Gödel-Prover-V2** (Princeton et al.) — открытая серия LLM для автоматического доказательства в Lean. Первая версия (Gödel-Prover, 2025) была представлена как "фронтирная" модель с открытым кодом, обученная на уникальном синтезированном наборе 1.64 млн формальных утверждений, полученных через автоформализацию. Улучшенная Gödel-Prover-V2 (Lin et al., 2025) добилась заметного скачка производительности: на сложном наборе PutnamBench её показатель успеха (Pass@32) оказался вдвое выше предыдущего SOTA, при том что размер модели меньше в 20 раз. Такой прогресс при меньших ресурсах подчёркивает эффективность подходов команды Gödel (сочетание синтеза данных и самокоррекции) в сравнении с более громоздкими системами.

- **APOLLO** — агентно-ориентированная система взаимодействия LLM с Lean, предложенная в 2025 году. *APOLLO* (**Automated Proof Repair via LLM and Lean collaboration**) действует как мета-алгоритм, который автоматически обрабатывает доказательства, генерируемые LLM, исправляя их и доводя до верного результата. Pipeline APOLLO включает ряд агентов: один модуль исправляет синтаксические ошибки с помощью Lean-компилятора, другой выделяет место ошибки в доказательстве, разбивает цель на подлеммы, подключает автоматические решатели и при необходимости вызывает LLM для незакрытых подцелей. После исправлений кусочки доказательства собираются и проверяются заново, итеративно до достижения корректности. Этот подход резко повысил эффективность: для моделей ~8 млрд параметров APOLLO достиг **84.9%** решения задач MiniF2F (на 8B-моделях, по состоянию на август 2025) при ограниченном бюджете попыток. Даже менее специализированные модели (например, небольшие OpenAI GPT) под управлением APOLLO подняли успешность решения с 3–7% до >40%. Код APOLLO открыт на GitHub, предлагая перспективный парадигм объединения LLM и формального компилятора для масштабируемого доказательства теорем.

### Автоформализация математических задач

- **FormaRL** – метод усиленного обучения для автоформализации без размеченных данных (Huang et al., 2025). Эта работа направлена на преодоление дефицита пар «неформальное утверждение – формальный код», который сдерживает прогресс в автоматизации доказательств. **FormaRL** обучает модель-формализатор, используя лишь небольшой объем сырого (неразмеченного) текста: в цикле RL модель получает *награду* за вывод за счёт двух инструментов – синтаксического чекера Lean4 и LLM-модуля проверки эквивалентности. Авторы собрали набор задач *uProof* (≈5000 утверждений из университетских курсов математики) и показали, что их подход повышает точность автоформализации в разы. Например, для базовой модели Qwen2.5-7B pass@1 на наборе ProofNet вырос с 4.04% до **26.15%**, а на более сложных задачах uProof – с 2.4% до 9.6%, используя всего 859 неразмеченных примеров. Также FormaRL улучшила обобщающую способность на задачах *поверх* существующих SOTA-формализаторов. Код и обученные модели опубликованы открыто (GitHub **THUNLP-MT/FormaRL**), что позволяет воспроизвести результаты.

- **StepFun-Formalizer** — семейство больших моделей (7В и 32В), предложенное Wu et al. (2025) для перевода текстовых задач в строго формальные утверждения Lean4. Авторы подчеркнули, что успешная автоформализация требует двух компонентов: (1) глубокого знания формального домена (библиотеки определений, теорем и т.д.) и (2) сильных умений рассуждать на естественном языке, чтобы правильно сопоставить неформальную задачу с формальным выражением. StepFun реализует стратегию обучения, которая укрепляет оба навыка. Во-первых, они автоматически дистиллировали большой датасет формальных фактов (для пополнения знаний модели) и синтезировали цепочки рассуждений «неформальный вопрос → формальное решение» по шаблонам (для обучения навыку выстраивания соответствия). Затем модель дообучается комбинацией методов: Supervised Fine-Tuning и RL с верификацией и рефином (RLVR). Итоговые модели **StepFun-Formalizer-7B/32B** обладают и обширными знаниями, и умением интерпретировать задачу. Модель 32В достигла новых рекордов: например, **BEq@1 = 40.5%** на наборе FormalMATH-Lite и 26.7% на ProverBench, превосходя всех предыдущих универсальных и специализированных автоформализаторов. Интересно, что данная работа принята Oral на AAAI 2026, свидетельствуя о важности темы. Код моделей StepFun доступен на Hugging Face и GitHub, облегчая их использование.

- **Autoformalizer with Tool Feedback (ATF)** — ещё один значимый шаг (Guo et al., 2025) к надёжной автоформализации. АТF интегрирует инструменты в цикл генерации: модель-формализатор во время вывода автоматически обращается к Lean4-компилятору для исправления синтаксиса и использует несколько LLM-"судей" для проверки смысловой консистентности перевода. Таким образом, если первоначальный вывод модели содержит ошибку (например, не компилируется в Lean или меняет смысл задачи), инструменты выявляют проблему и возвращают сигнал модели, побуждая её скорректировать результат. ATF обучается в несколько этапов: cold-start на синтетических данных с вызовами инструментов, затем итеративное обучение с экспертом (expert iteration) и оптимизация для стабильности исправлений. Результат – превосходство над базовыми моделями: АТF заметно превзошёл лучшие на тот момент формализаторы (включая Goedel-Formalizer-v2) по качеству формальных переводов. Более того, исследователи открыли большой синтетический датасет **Numina-ATF** (750 тыс. утверждений) сгенерированных формальных для дальнейших исследований автоформализации. Код и данные доступны на GitHub, что делает ATF ценным ресурсом для сообщества.

### Новые наборы задач и бенчмарки

- **FormalMATH** — крупнейший на сегодня бенчмарк по формальным доказательствам (Yu et al., 2025). Он содержит 5 560 задач, формализованных в Lean4, которые охватывают широкий спектр: от олимпиадных задач (ІМО, национальные олимпиады) до университетских теорем, по темам от алгебры и геометрии до анализа и дискретной математики. Ключевое достижение FormalMATH – масштаб получен без полного ручного ввода: авторы разработали human-in-the-loop конвейер автоформализации. Сначала специализированные LLM переводят задачи в Lean-формат, затем несколько LLM проверяют эквивалентность и **отсекают** ошибочные переводы с помощью опровержений (генерируя противоположные утверждения и проверяя их недоказуемость). Только наиболее перспективные формализации (~72% от исходных) отправляются эксперту для финальной правки, что сильно экономит трудозатраты. FormalMATH позволил провести всестороннюю оценку современных доказчиков: даже лучшие из них решили лишь ~16.5% задач при ограниченном бюджете попыток. Также выявлен дисбаланс: модели заметно лучше справляются, скажем, с алгеброй, чем с анализом, и чрезмерно полагаются на встроенные тактики вместо «творчества». Неожиданным открытием стало и то, что добавление человеком написанных неформальных подсказок *снижает* успех доказательства – видимо, из-за шума и неоднозначности живой речи, что мешает LLM в строгом режиме. FormalMATH (технический отчёт, 33 стр.) призван стать **надежным стресс-тестом** для новых моделей и стимулировать прогресс в АІ-доказательствах.

- **IndiMathBench** — свежий набор соревновательных задач, собранный при участии Microsoft Research (октябрь 2025). IndiMathBench включает 312 формально записанных теорем Lean4, взятых из задач Индийских математических олимпиад (INMO, RMO и др.). Для его создания применён *AI-поддерживаемый* человеко-машинный цикл: несколько LLM генерировали кандидаты формализаций, проверяя их через Lean и отладочный цикл, после чего удобный интерфейс позволял человеческому эксперту быстро просмотреть и исправить предложения. Такой подход существенно ускорил формализацию новых, ранее отсутствовавших в датасетах задач. Итоговый бенчмарк представляет интерес тем, что дополняет существующие (MiniF2F, PutnamBench) задачами из других региональных олимпиад, увеличивая разнообразие. Инструменты для работы с IndiMathBench (например, расширение VS Code для Lean) также разработаны в рамках проекта. Набор и код открыты на GitHub.

- **PutnamBench** — набор задач из знаменитого студенческого конкурса Putnam, представленный в конце 2024 года (Tsoukalas et al., NeurIPS 2024) и активно используемый в 2025. PutnamBench содержит ~500 формализованных задач (1938–2019 годы) из соревнования William Lowell Putnam, охватывающих разные разделы математики. Этот бенчмарк стал одним из стандартных тестов для новых AI-доказчиков: многие работы 2025 года (DeepSeek-Prover, Gödel-Prover-v2 и др.) отчитываются о количестве решённых задач именно на PutnamBench. Например, DeepSeek-Prover-V2 решила 49 задач этого набора, а ProofOptimizer научилась сокращать длинные доказательства решений Putnam-задач более чем наполовину. Наличие PutnamBench позволяет сравнивать модели на едином сложном наборе задач, требующих глубокого понимания и изящных доказательств.

- **MiniF2F** — кросс-системный бенчмарк олимпиадного уровня, созданный ещё в 2021 году, но в 2025 остаётся важным индикатором прогресса. MiniF2F включает ~500 задач из IMO, AIME, AMC, формализованных в нескольких ИТП (Lean, Isabelle, Coq). Все ключевые системы 2025 года измеряют успех и на MiniF2F: так, Kimina достигла ~80.7% (при очень большом числе выборок), DeepSeek-Prover-V2 – 88.9% (pass ratio), а LeanAbell-v2 и другие – ~70–78% при ограниченных 128 попытках. Прогресс по MiniF2F свидетельствует о росте возможностей моделей, хотя до 100% пока далеко – многие задачи (особенно по геометрии) остаются трудными даже для лучших ИИ.

- **CombiBench** — специализированный бенчмарк для **комбинаторной математики** (Liu et al., 2025). Он содержит 100 тщательно отобранных задач по комбинаторике из различных источников (IMO, USAMO, APMO, учебники и др.), предназначенных для оценки возможностей LLM решать сложные комбинаторные проблемы. CombiBench не столько про формальные доказательства, сколько про проверку *reasoning* модели в комбинаторных головоломках, требующих нестандартных шагов. В 2025 этот набор позволил выявить узкие места больших моделей – например, базовые GPT-4/Claude нередко ошибаются в таких задачах, показывая необходимость дальнейшего обучения с упором на структурированные рассуждения. CombiBench был представлен как submission на ICLR 2026 и привлёк внимание тем, что оценивает ИИ в области, близкой к олимпиадной математике, но вне чисто формального контекста. Он дополняет формальные бенчмарки, расширяя проверку AI на математическую смекалку.

- **IMO-Bench** — новый комплекс бенчмарков от DeepMind (Luong, Lockhart et al., 2025) для всесторонней оценки математических возможностей ИИ на уровне IMO. Согласно анонсу, **IMO-Bench** состоит из трёх частей, которые проверяют модели по различным аспектам: решение задач, генерация проверяемых доказательств и устойчивость к вариациям формулировок. Задачи прошли экспертизу международных специалистов по олимпиадной математике, а сами бенчмарки были использованы при разработке Gemini (для отслеживания прогресса модели). Предварительный технический отчёт (*"Towards Robust Mathematical Reasoning"*, EMNLP 2025) показывает оценку разных доступных моделей (Anthropic Claude, DeepSeek-V3, etc.) на IMO-Bench. Появление IMO-Bench важно тем, что акцент смещается на **проверку надёжности** и гибкости ИИ-решателей: задачи намеренно сформулированы разнообразно, чтобы выявить умение модели адаптироваться. Также включена проверка на *строгие формальные доказательства*, а не только на получение правильного ответа. Таким образом, IMO-Bench призван стать стандартом для будущих исследований на стыке неформального и формального ИИ-разума в математике.

## **Инструменты и проекты 2025 года для формальной математики**

**Lean Copilot** – фреймворк, превращающий большие языковые модели в **ассистентов** внутри системы Lean. Разработанный в Caltech (Song, Yang, Anandkumar, 2025), Lean Copilot позволяет запускать выводы LLM *непосредственно* в среде Lean, что даёт возможность создать интерактивные инструменты поддержки доказательств. По сути, Lean Copilot соединяет Python-обёртку для LLM (локально или через API) с интерфейсом Lean: пользователи могут запрашивать у модели подсказки следующего шага, автозавершение доказательства для текущей цели или подбор нужной теоремы из библиотеки (premise selection). В отличие от полностью автономных доказчиков, Copilot действует **в паре с человеком**: математик контролирует процесс, а ИИ помогает рутинными или сложными местами. Эксперименты показали, что такой режим заметно ускоряет работу в Lean по сравнению с чисто ручным доказательством и стандартной автоматизацией Lean-тактиками. Все компоненты Lean Copilot открыты под лицензией МІТ и уже интегрированы в экосистему LeanDojo – это снижает порог для внедрения LLM в практику формализации математики.

- **Lean Finder** — семантическая поисковая система по математической библиотеке Lean (mathlib), представленная Lu et al. в 2025. Lean Finder решает проблему, с которой часто сталкиваются пользователи ИТП: «Как найти нужную теорему или лемму в огромной базе mathlib по краткому описанию?». Существующие поиск-плагины в Lean в основном "информализуют" запрос – переводят естественный язык в формальное приближенно – но не учитывают реальный контекст запроса математика. Lean Finder идёт от обратного: он анализирует тысячи реальных обсуждений на форумах Lean (Zulip и др.), чтобы выяснить, как люди спрашивают о математических фактах, затем на основе этого синтезирует тренировочные запросы и специально тонко настраивает эмбеддинги для понимания намерений пользователя. Дополнительно система учится на откликах (feedback) – какие результаты выбирались, что полезно – чтобы улучшать ранжирование. В итоге Lean Finder достигает >30% прироста качества поиска по сравнению с предыдущими инструментами и даже превосходит GPT-4, использованного как поиск, в умении угадывать, какой именно факт нужен математику. Проект доступен онлайн: leanfinder.github.io предлагает удобный интерфейс, где можно задать вопрос по математике (на английском) – например, "существует ли изоморфизм между... при таких условиях?" – а система выдаст соответствующую теорему Lean и ссылку на её доказательство в mathlib. Lean Finder тем самым **снижает порог входа** в формальную математику для новых пользователей и ускоряет работу опытных, позволяя быстро находить нужные результаты.

- **ProofGym** — инфраструктурный проект, облегчающий обучение и тестирование LLM-доказчиков на разных системах (Li et al., NeurIPS MATH-AI Workshop 2025). ProofGym предоставляет единый API на Python для взаимодействия с гетерогенными интерактивными доказателями – поддерживаются Coq, Isabelle/HOL, Lean – скрывая различия между ними. Он поддерживает как генерацию целых доказательств, так и пошаговый интерактивный режим, а также позволяет выполнять batched-верификацию (параллельно проверять множество доказательств) для ускорения экспериментов. ProofGym вводит единый формат описания состояния/результата доказательства, что упрощает логирование и сбор датасетов из взаимодействий модели с разными ИТП. Предварительные эксперименты показали значительный рост пропускной способности при проверке и поиске доказательств, без потери скорости на отдельный запрос. Проект нацелен на исследователей: c ProofGym они могут писать и сравнивать алгоритмы обучения доказчиков, которые будут сразу совместимы с несколькими системами. Таким образом, ProofGym унифицирует платформу для нейро-символьных исследований в доказательствах, позволяя переносить находки из одной системы (например, Lean) в другую (Coq) с минимальными усилиями.

- **ProofOptimizer** — инструмент **оптимизации формальных доказательств**, представленный командой Принстон/Caltech (Gu et al., 2025). Проблема: современные RL-доказчики (как AlphaProof) генерируют доказательства длиной в тысячи строк – они проходят проверку ядром, но слишком громоздки и трудны для понимания человеком. ProofOptimizer обучен автоматически сокращать и упрощать такие доказательства, сохраняя их корректность. Модель не требует ручной разметки сокращённых доказательств – вместо этого используется итеративное самосовершенствование (expert iteration): модель пытается укорачивать доказательство, Lean проверяет, что оптимизированная версия по-прежнему доказывает теорему, и это входит в обучение как положительный пример. На этапе вывода ProofOptimizer применяется к готовому длинному доказательству циклично: сокращает его шаг за шагом, каждый раз убеждаясь через Lean, что доказательство ещё валидно. Результаты впечатляют: доказательства задач MiniF2F стали короче на 87% (!), решения PutnamBench – на 57%, а громоздкие доказательства задач IMO (сгенерированные ранними версиями проверов) сократились на ~49%. Более компактные доказательства не только легче читать – они и проверяются Lean'ом гораздо быстрее, и даже могут улучшить обучение новых моделей, если использовать их как обучающие примеры. ProofOptimizer тем самым снимает бутылочное горлышко логической избыточности, делая вклад ИИ-доказчиков более пригодным для анализа математиками.

**Вывод:** 2025 год ознаменовался бурным прогрессом на стыке ИИ и формальной математики. Появились всё более мощные доказчики теорем (от гигантских RL-моделей, берущих олимпиады, до открытых компактных проверов), улучшились алгоритмы автоформализации текстовых математических задач, созданы новые бенчмарки и инструменты для оценки, а также вспомогательные сервисы для математиков. Особенно примечательно, что крупные индустриальные лаборатории (Google DeepMind, Microsoft, OpenAI в сотрудничестве) активно вовлечены: например, DeepMind поднял планку состязательного решения задач до уровня золота IMO, а совместные усилия академических групп подарили сообществу открытые инструменты вроде Lean Copilot, ProofGym, новых датасетов и моделей. Всё это приближает цель, когда ИИ станет не просто решателем задач, но и полезным помощником математиков – способным понимать неформальные аргументы, переводить их в строгие доказательства и даже подсказывать новые идеи для теорем. Такое слияние нейросетей с формальными методами обещает революционизировать и обучение, и практику математических исследований в ближайшем будущем.

---

## **Источники**

### Коллекция ресурсов

- **[DL4TP — Deep Learning for Theorem Proving](https://github.com/zhaoyu-li/DL4TP)** — репозиторий с обширной коллекцией работ по глубокому обучению для доказательства теорем (COLM 2024). Включает разделы по автоформализации, выбору предпосылок, генерации шагов доказательства, поиску доказательств, датасетам и многому другому.

### Основные публикации и источники

1. [A Survey on Deep Learning for Theorem Proving](https://arxiv.org/html/2404.09939v1) — arXiv
2. [Olympiad-level formal mathematical reasoning with reinforcement learning](https://www.nature.com/articles/s41586-025-09833-y) — Nature 2025
3. [Advanced version of Gemini with Deep Think officially achieves gold-medal standard at the IMO](https://deepmind.google/blog/advanced-version-of-gemini-with-deep-think-officially-achieves-gold-medal-standard-at-the-international-mathematical-olympiad/) — Google DeepMind Blog
4. [AI achieves silver-medal standard solving International Mathematical Olympiad problems](https://deepmind.google/blog/ai-solves-imo-problems-at-silver-medal-level/) — Google DeepMind Blog
5. [Kimina-Prover Preview: Towards Large Formal Reasoning Models with Reinforcement Learning](https://arxiv.org/abs/2504.11354) — arXiv
6. [DeepSeek-Prover-V2: Advancing Formal Mathematical Reasoning via Reinforcement Learning for Subgoal Decomposition](https://arxiv.org/abs/2504.21801) — arXiv
7. [Leanabell-Prover-V2: Verifier-integrated Reasoning for Formal Theorem Proving via Reinforcement Learning](https://arxiv.org/abs/2507.08649) — arXiv
8. [Gödel-Prover](https://yangky11.github.io/) — Kaiyu Yang's page
9. [APOLLO: Automated LLM and Lean Collaboration for Advanced Formal Reasoning](https://arxiv.org/html/2505.05758v4) — arXiv
10. [FormaRL: Efficient Reinforcement Learning Framework for Autoformalization](https://openreview.net/pdf?id=Z2El1U94bq) — OpenReview
11. [StepFun-Formalizer: Unlocking the Autoformalization Potential of LLMs through Knowledge-Reasoning Fusion](https://arxiv.org/abs/2508.04440) — arXiv
12. [Autoformalizer with Tool Feedback](https://arxiv.org/html/2510.06857v1) — arXiv
13. [FormalMATH: Benchmarking Formal Mathematical Reasoning of Large Language Models](https://arxiv.org/abs/2505.02735) — arXiv
14. [IndiMathBench](https://www.microsoft.com/en-us/research/wp-content/uploads/2025/10/IndiMathBench_MS_hosting.pdf) — Microsoft Research
15. [ProofOptimizer: Training Language Models to Simplify Proofs without Human Demonstrations](https://arxiv.org/abs/2510.15700) — arXiv
16. [Towards Robust Mathematical Reasoning / IMO-Bench](https://arxiv.org/html/2511.01846v1) — arXiv
17. [Towards Large Language Models as Copilots for Theorem Proving in Lean](https://ar5iv.org/abs/2404.12534) — arXiv
18. [Lean Finder: Semantic Search for Mathlib That Understands User Intents](https://ar5iv.labs.arxiv.org/html/2510.15940) — arXiv
19. [ProofGym: Unifying LLM-Based Theorem Proving Across Formal Systems](https://openreview.net/forum?id=RrSQxcg6Nu) — OpenReview
20. [LeanDojo: Theorem Proving with Retrieval-Augmented Language Models](https://arxiv.org/abs/2306.15626) — arXiv
21. [Exploring the beauty of pure mathematics in novel ways](https://deepmind.google/blog/exploring-the-beauty-of-pure-mathematics-in-novel-ways/) — Google DeepMind Blog
22. [Discovering novel algorithms with AlphaTensor](https://deepmind.google/blog/discovering-novel-algorithms-with-alphatensor/) — Google DeepMind Blog
23. [FunSearch: Making new discoveries in mathematical sciences using Large Language Models](https://deepmind.google/blog/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models/) — Google DeepMind Blog
24. [Competition-Level Code Generation with AlphaCode](https://arxiv.org/abs/2203.07814) — arXiv
25. [GPT-f: Generative Language Modeling for Automated Theorem Proving](https://arxiv.org/abs/2009.03393) — arXiv
26. [MiniF2F: A cross-system benchmark for formal olympiad-level mathematics](https://github.com/openai/miniF2F) — GitHub
27. [Lean (proof assistant)](https://en.wikipedia.org/wiki/Lean_(proof_assistant)) — Wikipedia
28. [Isabelle (proof assistant)](https://en.wikipedia.org/wiki/Isabelle_(proof_assistant)) — Wikipedia
29. [HOL Light](https://en.wikipedia.org/wiki/HOL_Light) — Wikipedia
30. [The Coq Proof Assistant](https://zenodo.org/records/11551307) — Zenodo
31. [Lean Reference Manual](https://lean-lang.org/doc/reference/latest/Introduction/) — Lean Lang
32. [CoqHammer: Strong Automation for Program Verification](https://popl18.sigplan.org/details/CoqPL-2018/2/CoqHammer-Strong-Automation-for-Program-Verification) — CoqPL
33. [Autoformalization: Bridging Informal and Formal Math](https://www.emergentmind.com/topics/autoformalization) — Emergent Mind
34. [A New Approach Towards Autoformalization](https://arxiv.org/abs/2310.07957) — arXiv
35. [Rethinking and Improving Autoformalization](https://openreview.net/forum?id=hUb2At2DsQ) — OpenReview
36. [AI to Assist Mathematical Reasoning: A Workshop](https://www.nationalacademies.org/projects/DEPS-BMSA-23-01) — National Academies
37. [HOList: Reasoning with Transformer-based Models](https://openreview.net/pdf?id=Ozp1WrgtF5_) — OpenReview
38. [StepFun-Formalizer models](https://huggingface.co/stepfun-ai/StepFun-Formalizer-32B) — Hugging Face
39. [StepFun-Formalizer](https://github.com/stepfun-ai/StepFun-Formalizer) — GitHub
40. [APOLLO](https://github.com/ospanov/APOLLO) — GitHub
41. [THUNLP-MT/FormaRL](https://github.com/THUNLP-MT/FormaRL) — GitHub
42. [LeanDojo](https://leandojo.org/) — Official site
43. [Lean Finder](https://leanfinder.github.io/) — Official site
