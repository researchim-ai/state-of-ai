# Синтетические данные: современные подходы, инструменты, оценка качества и правовые аспекты (2023–2025)

## Введение

**Синтетические данные** – это искусственно созданные данные, которые имитируют характеристики реальных данных, но не содержат напрямую взятой из них информации. Проще говоря, под синтетическими данными понимается «искусственно аннотированная информация, сгенерированная компьютерными алгоритмами или симуляциями».  Потребность в синтетических наборах возникает, когда реальные данные недоступны или крайне конфиденциальны, например, из-за требований приватности (как в случае с финансовыми транзакциями или медицинскими записями). В эпоху строгих законов о защите данных – таких как Общий регламент ЕС по защите данных (GDPR) и Калифорнийский закон о конфиденциальности (CCPA) – доступ к реальным данным и их обмен сильно ограничены. Синтетические данные предлагают выход из этой ситуации, позволяя получать **дополнительные данные** для обучения моделей, проведения тестирования и других задач без риска раскрытия личной информации.

Основная идея синтетической генерации – обучить модель на реальном датасете и затем сгенерировать новый массив данных, статистически похожий на оригинальный, но не содержащий **персонально идентифицируемой информации**. Современные генеративные модели способны изучать распределение настоящих данных и порождать **высокодостоверные (high-fidelity)** образцы, максимально сохраняющие статистические свойства оригинала, при этом обеспечивая **конфиденциальность** за счет разрыва связи с реальными индивидами. Разнообразные подходы применяются для генерации синтетических данных – от традиционных статистических методов до передовых моделей глубинного обучения. В последние годы наибольшего успеха достигли **генеративные модели**: вариационные автокодировщики (VAE), генеративно-состязательные сети (GAN), нормализующие потоки, диффузионные модели и большие языковые модели (LLM). Эти методы изначально продемонстрировали впечатляющие результаты на однородных данных – прежде всего **текстах и изображениях**, – и теперь адаптируются для более сложных структур, таких как **табличные данные**. Таким образом, синтетические данные сегодня рассматриваются как перспективное решение проблемы нехватки качественных данных и ограничений доступа, позволяющее расширять датасеты, улучшать **разнообразие** и **справедливость** выборок, а также соблюдать требования приватности при обмене информацией.

## Подходы к генерации синтетических данных

### Текстовые данные

Генерация синтетического текста получила мощный импульс благодаря развитию **больших языковых моделей (Large Language Models, LLM)**. Современные LLM (например, GPT-3.5, GPT-4 и их открытые аналоги вроде LLaMA) способны на основе обученных знаний генерировать осмысленные тексты практически любой тематики. В 2023–2024 гг. исследователи активно экспериментировали с использованием LLM для создания синтетических текстовых датасетов, предлагая их как альтернативу ручной разметке и сбору данных. Такой подход позволяет автоматически получать большие корпуса примеров для обучения моделей – например, наборы вопросов и ответов, классы текстов для классификации, диалоги для чат-ботов и т.д.

**Основной метод** заключается в подаче модели запроса (промпта), описывающего требуемые данные. LLM генерирует тексты, которые затем могут быть отфильтрованы и размечены (в некоторых случаях сама модель присваивает метки своим ответам). Например, можно запросить у языковой модели придумать десятки отзывов пользователей на продукт с разными эмоциональными оттенками и получить синтетический набор для задачи анализа тональности. Hugging Face в 2024 году представила удобный инструмент **Synthetic Data Generator**, позволяющий в несколько шагов генерировать текстовые датасеты по описанию на естественном языке, используя LLM под капотом. Таким образом, создание синтетического текста перестало быть уделом экспертов NLP – появились инструменты, делающие этот процесс **доступным без кода**.

Однако, у генерации текста LLM-моделями есть и ограничения. Последние исследования показывают, что **эффективность синтетических текстов** сильно варьируется от задачи к задаче. На объективных заданиях (например, классификация тем новостей) модели, обученные на синтетических данных, могут приближаться по качеству к обучению на реальных данных. Но на субъективных или тонких задачах (например, анализ настроений, где много нюансов) качество может заметно проседать. Причины – возможные искажения в распределении синтетических данных, **галлюцинации** модели или отсутствие в них тонких контекстуальных признаков. Кроме того, синтетически сгенерированный текст может непреднамеренно включать факты из обучающего корпуса LLM, что несет риск утечки исходных данных. Чтобы повысить реалистичность, применяются методы **контроля и фильтрации**: регулируется температура генерации, исключаются повторяющиеся фразы, сравнивается распределение n-грамм с реальным корпусом и т.д. В целом, LLM сегодня – один из главных инструментов текстовой синтетики, особенно ценен для **разметки данных** и **обогащения обучающих выборок** (data augmentation).

### Изображения

Для синтетических изображений ключевую роль сыграли **генеративно-состязательные сети (GAN)** и **диффузионные модели**. GAN, впервые предложенные в 2014 году, долгое время доминировали в генерации реалистичных изображений: современные варианты (например, StyleGAN2) способны порождать высококачественные изображения лиц, объектов, сцен. Ключевой показатель качества синтезированных картинок – насколько они **неотличимы от реальных**. В качестве метрики стандартом де-факто стал *Fréchet Inception Distance (FID)* – расстояние между распределениями признаков, извлеченных нейросетью Inception из набора реальных и сгенерированных изображений. Показано, что к 2024 году FID остаётся *основным* численным критерием для оценки генеративных моделей: чем ниже FID, тем ближе синтетические изображения статистически к настоящим. Современные GAN-модели достигли весьма низких FID на ряде наборов (менее 3–5 для лиц), что указывает на их высокую достоверность.

В 2022–2023 гг. на смену GAN стремительно пришли **диффузионные модели**, продемонстрировавшие выдающееся качество и устойчивость генерации. Диффузионные модели (например, **Stable Diffusion**, **DALL·E 2**) генерируют изображения путем пошагового *обратного диффузионного процесса*: начиная с шума, они итеративно «очищают» его, формируя образ. Преимущество – стабильное обучение и способность воспроизводить **мелкие детали**, благодаря чему синтетические изображения становятся фотореалистичными. Исследования показывают, что диффузионные модели превосходят GAN по детализации и разнообразию, особенно на сложных сценах. По мере совершенствования диффузионных генераторов отличить синтез от фото становится всё сложнее – разница между реальными и созданными изображениями постепенно стирается.

Помимо нейросетевых методов, активно используются и **симуляции** для визуальных данных. Например, движки графики (Unity, Unreal Engine) позволяют генерировать сцены для обучения систем компьютерного зрения – от дорожных ситуаций для автопилотов до виртуальных полок магазинов для систем роботизированного зрения. В сочетании с рендерингом 3D-моделей и физическими движками такие симуляции дают **управляемый поток данных**: можно программно менять освещение, ракурсы, появление редких объектов. Это ценно там, где сбор реальных изображений затруднён или опасен (например, сцены ДТП, экстремальные погодные условия). Одним из направлений 2023 года стало совмещение диффузионных моделей с текстовым управлением сценами. Так, на NeurIPS 2023 был представлен подход, где предварительно обученный диффузионный генератор дообучается и с помощью текстовых описаний (через модель CLIP) направляется на создание сцен с редкими объектами, например **машинами скорой помощи на дороге**. Далее изображения с добавленными объектами проходят супер-резолюсьон (повышение разрешения) и используются для тренировки моделей детекции объектов. Такой **синтез по запросу** решает проблему нехватки кадров с особыми случаями и уже применяется для улучшения распознавания в автономном вождении.

### Табличные данные

**Табличные (структурированные) данные** – одна из самых трудных областей для генерации. Это данные в формате строк и столбцов (базы данных, таблицы с признаками), широко используемые в финансах, медицине, бизнес-аналитике. Сложность в том, что табличные наборы часто содержат *разнородные типы* столбцов (числа, категории, тексты), сложные зависимости между признаками, пропуски, дисбаланс классов. Генеративные модели, успешные на изображениях и текстах, напрямую не всегда справляются с сохранением всех нюансов табличного распределения. Тем не менее, прогресс последних лет затронул и эту сферу.

**Классические подходы** к синтезу таблиц включают статистическое моделирование: оценка распределения каждого признака (с учетом корреляций) и последующая выборка из этих оценок. Например, метод *копул* моделирует многомерное распределение данных через функции копулы и генерирует новые точки, сохраняя эмпирические зависимости. Однако такие методы трудоемки для высокоразмерных данных с нелинейными связями.

**Генеративные модели на основе DL** стали продвигаться и в табличный домен. Первыми были адаптированы **GAN**: так появились модели *CTGAN* и *CTAB-GAN*, учитывающие категориальные колонки и дисбаланс классов через условное поколение. В медицине применялись специальные GAN (например, *medGAN*) для синтеза электронных медицинских карт. Также используются **Variational Autoencoder (VAE)** и **Normalizing Flows** – они стремятся покрыть распределение данных в латентном пространстве и выборкой оттуда получать новые записи.

**Диффузионные модели** дошли и до таблиц: недавние работы (TabDDPM, TabDiff, FinDiff и др.) адаптировали диффузионный процесс к табличным данным. Например, *TabDDPM-EHR* успешно генерирует синтетические медицинские записи, сохраняя статистические свойства оригинала. В финансовом секторе предложен *FinDiff* – диффузионная модель для создания высокодостоверных финансовых таблиц, применимых в регуляторных задачах. Эти модели показали, что диффузионный подход способен уловить сложные распределения смешанных типов данных и выдавать образцы, не отличающиеся по ключевым метрикам от реальных. Более того, модификации позволяют адресовать специфические проблемы: так, *Imb-FinDiff* генерирует дополнительно данные для **миноритарных классов**, борясь с дисбалансом в финансовых наборах, а *MissDiff* успешно обходится с пропущенными значениями посредством обучения с маскированием.

**Большие языковые модели (LLM)** открыли новое направление – генерация таблиц с учётом **контекстных знаний**. Идея в том, что LLM, предобученные на огромных объемах текстов, уже владеют обобщенными знаниями (например, в медицине или финансах) и здравым смыслом. Их можно либо *специально дообучить* на табличных данных, либо использовать через *prompt engineering*. Пример: метод **EPIC (2024)** формирует промпты для GPT-3.5 или LLaMA-2, прося сгенерировать записи для малочисленных классов в табличном наборе – фактически «вписать» недостающие примеры на основе знаний модели. Аналогично, модель **CLLM (ICML 2024)** использует внутренние знания GPT-4 для генерации табличных данных в условиях, где реальных данных мало. LLM хорошо поддерживают **логические ограничения**: например, они «знают», что возраст не может быть отрицательным, а дети в базе не могут быть указаны как женатые. Благодаря этому синтетические таблицы от LLM более **семантически корректны** и соответствуют доменной специфике. Подходы делятся на *prompt-based* (без обучения, только через запросы) и *fine-tuning* (дообучение LLM на табличном корпусе). К началу 2025 г. уже существуют десятки экспериментальных LLM-систем для табличной генерации (TabGPT, GReaT, HARMONIC и др.), демонстрирующие конкурентное качество.

Таким образом, для каждой модальности данных сформировались свои передовые методы синтеза: **тексты** генерируются LLM моделями, **изображения** – диффузионными моделями и GAN, **таблицы** – комбинацией глубоких генеративных моделей с учётом гетерогенности данных, а также LLM с экспертизой в предметной области.

## Актуальные инструменты и библиотеки (2023–2025)

Современная экосистема синтетических данных богата как исследовательскими разработками, так и практическими инструментами с открытым исходным кодом. Ниже перечислены ключевые библиотеки и технологии, популярные в 2023–2025 годах:

* **Synthetic Data Vault (SDV)** – комплексная Python-библиотека для генерации синтетических данных, особенно табличных. Проект SDV включает модели для одиночных таблиц, связанных таблиц и временных рядов, позволяя пользователю обучить генератор на своем датасете и получить синтетический. SDV обобщает многие подходы (GaussianCopula, CTGAN, TVAE и др.) и предоставляет единый интерфейс для их использования. Это своего рода «универсальный магазин» синтетических данных, где можно выбрать подходящий генератор под свой тип данных. Проект активно развивается (поддерживается открытым сообществом и Data Science Lab MIT) и к 2025 году стал промышленным стандартом для табличной синтетики.

* **SDMetrics** – связанная библиотека, предназначенная для оценки качества синтетических данных. Она предлагает набор метрик, сравнивающих синтетический датасет с реальным по разным критериям. SDMetrics автоматически вычисляет статистические расстояния для каждого поля, оценивает сохранение корреляций между колонками, качество моделирования редких категорий и др. Кроме того, библиотека содержит метрики полезности – позволяет запустить схему Train on Synthetic, Test on Real и измерить просадку качества моделей. SDMetrics стала неотъемлемым инструментом при внедрении синтетических данных: с ее помощью проверяют, достаточно ли **реалистичен** сгенерированный набор и не утратил ли он **полезность** для целевых задач.

* **Диффузионные модели и библиотеки генерации изображений.** Для работы с современными диффузионными моделями существуют готовые фреймворки. **HuggingFace Diffusers** – библиотека, предоставляющая реализации популярных диффузионных моделей (Stable Diffusion, Latent Diffusion и др.) с возможностью тонкой настройки процесса генерации. Появились и узкоспециализированные инструменты, например, **DreamBooth** (адаптация диффузионной модели под конкретный набор изображений) – полезно для синтеза данных в узкой доменной области. Для **управляемой генерации** широко используется связка диффузионной модели с CLIP (Contrastive Language–Image Pre-training) – это позволяет задавать через текст или образец, *какие* сцены или объекты нужны. Таким образом, пакет технологий вокруг Stable Diffusion и подобных моделей стал важным инструментарием для получения синтетических изображений в 2023–2025 гг., особенно после открытого выпуска весов моделей (Stable Diffusion v1 в 2022, v2 в 2023 и последующих версий).

* **Большие языковые модели (LLM) для синтетического текста.** В практических сценариях для генерации текстовых данных часто применяются облачные API: **OpenAI GPT-3.5/GPT-4**, **Anthropic Claude**, **Google PaLM** и др. Эти модели по запросу генерируют текст заданного формата (будь то диалог, описания, классифицированные примеры). Для интеграции LLM в конвейер данных появились обертки и инструменты, упрощающие массовую генерацию. К примеру, библиотека **LangChain** позволяет автоматизировать цикл: перебрать список промптов, собрать ответы модели и сохранить их в датасет. Также, как упоминалось, Hugging Face разработала **Synthetic Data Generator** – веб-интерфейс, где пользователь описывает нужный датасет, а на выходе получает сгенерированный набор (например, синтетические отзывы с метками). Кроме того, открытые модели вроде **LLaMA-2**, **Mistral** можно развернуть локально и использовать для синтеза конфиденциальных текстовых данных, чтобы не отправлять их внешним сервисам. Инструменты разметки данных (например, Snorkel, Databricks Labeling) интегрируются с LLM для генерации вариантов разметки и новых примеров, ускоряя подготовку обучающих выборок.

* **Коммерческие платформы синтетических данных.** Наряду с open-source решениями, в последние годы выросло число коммерческих сервисов, предоставляющих генерацию синтетических данных «под ключ». Например, компания **Mostly AI** специализируется на синтезе персональных данных клиентов для банков и страховых компаний – их платформа генерирует демографические и транзакционные данные, сохраняя корреляции, и утверждает соответствие требованиям GDPR (путем оценки риска реидентификации). Другой пример – **Gretel.ai**, предлагающая API для синтеза текстов, временнЫх рядов и табличных данных с настройкой приватности. В области изображений – сервисы вроде **Synthesis AI** создают на заказ наборы фотореалистичных лиц, движений людей, которые можно использовать для обучения систем распознавания (при этом контрактно гарантируется, что все лица вымышлены). Эти инструменты обычно платные, но востребованы в индустрии, где нет ресурсов разрабатывать свои генеративные модели. Они часто объединяют несколько подходов (GAN, диффузия, симуляция) и включают встроенные метрики качества и проверки приватности.

В 2023–2025 годах перечисленные инструменты значительно упростили применение синтетических данных на практике. Если ранее требовалось самим реализовывать и обучать GAN или VAE, то теперь доступны готовые решения, позволяющие сфокусироваться на задаче – будь то расширение датасета для модели или обезличивание чувствительной информации. Сообщество активно обменивается **кодом и лучшими практиками** (например, репозиторий Awesome Synthetic Data на GitHub собирает последние исследования и библиотеки). Это свидетельствует о зрелости экосистемы синтетических данных и её готовности к масштабному внедрению.

## Методы оценки качества синтетических данных

Критически важно не только сгенерировать данные, но и убедиться, что они **качественные** – то есть пригодны для использования и одновременно не раскрывают конфиденциальной информации. В литературе качество синтетических данных рассматривается по трем основным измерениям: **достоверность (fidelity)**, **полезность (utility)** и **приватность (privacy)**. Ниже мы рассмотрим, что означает каждое из этих понятий и какие метрики используются для их количественной оценки в разных типах данных.

### Fidelity (сохранение достоверности данных)

**Fidelity** характеризует, насколько хорошо синтетические данные воспроизводят статистические свойства оригинального набора. Высокая достоверность означает, что распределения признаков, их взаимосвязи и общие паттерны в синтетических данных практически идентичны реальным. Хотя высокая fidelity не гарантирует автоматического успеха на практике (можно представить идеально «скопированные» данные, которые, тем не менее, не улучшат модель), она считается *необходимым условием* структурного реализма синтетического датасета.

**Методы оценки fidelity** принято разделять на три категории:

* *Покомпонентные метрики (column-wise)* – сравнивают по отдельности распределения каждого признака в реальных и синтетических данных. Для числовых колонок часто используют расстояние Васерштейна или тест Колмогорова–Смирнова, оценивая, совпадают ли распределения величин. Для категориальных признаков применяют дивергенцию Дженсена–Шеннона или полное вариационное расстояние между распределениями частот. По сути, эти метрики проверяют, не «съехали» ли средние значения, дисперсии, гистограммы синтетики относительно оригинала.

* *Парные метрики (pair-wise)* – оценивают сохранение зависимостей между парами признаков. Например, вычисляют матрицу корреляций Пирсона для всех пар числовых полей в реальных данных и сравнивают с аналогичной матрицей для синтетических данных. Разница (по нормам или метрике типа MSE) показывает, насколько хорошо генератор сохранил линейные взаимосвязи. Для категориальных пар можно строить таблицы сопряженности и сравнивать меры сходства между реальной и синтетической таблицами (вплоть до суммы по всем ячейкам). Такие метрики вскрывают, не нарушены ли важные корреляции или ассоциации в данных.

* *Многомерные метрики (joint distribution)* – пытаются напрямую измерить расстояние между многомерным распределением всего набора данных и распределением синтетического набора. В простейшем случае можно использовать эмпирическую вычисленную дивергенцию Кульбака–Лейблера или тотальное вариационное расстояние по всем измерениям (что трудно для больших данных). В практике применяют эвристические метрики: например, **GMU (Granular Metrics Utility)** – сочетание нескольких парных и покомпонентных показателей; или метрики на основе покрываемости и разнообразия (Coverage). Последние измеряют, сколько уникальных комбинаций (или кластеров) реальных данных покрыто синтетическими (и наоборот), отражая способность синтетики воспроизвести как распространенные, так и редкие паттерны оригинала.

Для изображений понятие fidelity тоже важно: здесь, как упоминалось, используется **FID** – если синтетические изображения имеют такой же распределение активаций нейросети, как и реальные, то FID будет низким. Также применяют *Inception Score (IS)* – метрику, оценивающую одновременно разнообразие и реалистичность изображений (высокий IS желателен). Для текстовых данных прямых аналогов FID нет, но можно ориентироваться на показатели языковой модели: например, считать **перплексию** (насколько тексты кажутся естественными для внешней языковой модели) – если перплексия на синтетическом корпусе близка к таковой на реальном, то распределение слов и фраз воспроизведено хорошо. Также иногда обучают внешний классификатор, пытающийся отличить реальные тексты от синтетических (аналог теста Тьюринга): если классификатор еле справляется, значит fidelity высокая.

Стоит подчеркнуть: **достоверность** – необходимый, но не достаточный критерий. Синтетические данные могут идеально повторять статистику, но оказаться бесполезными для практики или небезопасными с точки зрения приватности. Тем не менее, проверка fidelity – первый шаг: она выявляет явные артефакты (например, смещенные распределения, нелогичные комбинации значений) и дает уверенность, что синтетика *структурно напоминает* реальные данные.

### Utility (полезность для моделей и аналитики)

**Utility** синтетических данных отражает, насколько хорошо они выполняют свою прикладную задачу по сравнению с реальными данными. Иначе говоря, полезность показывает, пригоден ли синтетический набор для обучения моделей, проведения исследований, тестирования гипотез **так же**, как если бы мы использовали оригинальные данные. Высокая utility означает, что модели, алгоритмы и выводы, полученные на синтетических данных, сопоставимы по качеству с теми, что получаются на реальных данных.

На практике utility часто измеряется через схемы обучения и тестирования. Один из распространенных протоколов – **Training on Synthetic, Testing on Real (TSTR)**. Он работает так: исходные реальные данные делятся на train/test, на обучающей части генерируется синтетический набор, затем обучаются две модели – первая на реальных данных, вторая на синтетических (но той же размерности). Обе модели оцениваются на **одинаковом реальном тестовом наборе**, и их качество (точность, F1, AUC и т.п.) сравнивается. Если модель, обученная на синтетических данных, показывает результат близкий к модели, обученной на реальных, то synthetic utility считается высокой. Идеально, если разница статистически незначима – это значит, что синтетические данные несут ту же пользу для обучения, что и реальные.

Другой подход – **Train on Real, Test on Synthetic (TRTS)** или его вариации, когда синтетические данные применяются в качестве тестового полигона. Например, можно обучить модель на реальных данных, а затем проверить, насколько хорошо она обобщается на синтетически сгенерированные случаи. Это особенно актуально для проверок на *краевых случаях*: если синтетический набор был создан для включения редких или экстремальных ситуаций, то модель, устойчиво работающая на них, имеет повышенную надежность. Тут utility проявляется как покрытие сценариев, не встречавшихся в ограниченной реальной выборке.

Кроме схем с обучением, полезность проверяется **аналитически**. Например, для медицинских данных – проводят те же статистические анализы (регрессии, гипотезы) на реальном и синтетическом наборах и смотрят, совпадают ли выводы. Если по синтетическим данным исследователь пришел бы к тем же выводам (скажем, те же значимые факторы риска заболевания), что и по оригинальным данным, – utility высокая.

Важно, что **fidelity и utility не всегда коррелируют идеально**. Бывают случаи, когда синтетический набор очень похож на оригинальный по распределениям, но небольшие отличия приводят к ощутимой разнице в качестве моделей. И наоборот, можно пожертвовать некоторой точностью воспроизведения распределения, но специально усилить важные для модели случаи – и тогда utility возрастет. Поэтому при оценке качества синтетических данных рекомендуется смотреть на оба аспекта. Современные инструменты (те же SDMetrics) вычисляют интегральные показатели полезности, например усредненную относительную разницу метрик качества моделей на синтетических vs реальных данных. В целом, **высокая полезность** означает, что синтетические данные действительно могут заменить реальные в конкретной задаче – модель на них обученная не теряет в прогнозирующей силе более чем на несколько процентов.

### Privacy (приватность и защита от идентификации)

Третий столп качества – **приватность**. Смысл синтетических данных во многом теряется, если они по кусочкам повторяют исходные записи и тем самым нарушают конфиденциальность. Поэтому оценить, насколько синтетический набор **избавлен от утечки личной информации**, крайне важно перед его распространением или использованием.

Основной вопрос: может ли злоумышленник, имея доступ к синтетическим данным, извлечь из них сведения о конкретных реальных людях или записях? Если синтетическая модель *переобучилась* на оригинале и выдала почти точные копии некоторых строк, приватность под угрозой. Разработано несколько метрик, которые позволяют количественно оценить риск:

* **Distance to Closest Record (DCR)** – метрика «расстояние до ближайшей записи». Для каждой синтетической записи вычисляется расстояние (например, евклидово для числовых признаков, либо смесь метрик для категориальных) до ближайшей реальной записи в оригинальном датасете. Если в среднем это расстояние слишком мало, есть повод беспокоиться: некоторые синтетические точки почти совпадают с реальными, что указывает на возможную утечку (модель попросту запомнила эти точки). Высокие значения DCR предпочтительны – они означают, что каждая синтетическая запись существенно отличается от любого реального аналога, то есть прямого копирования нет.

* **Атака по атрибутам (Attribute Inference Attack)** – модель оценки приватности, в которой предполагается, что злоумышленнику известна часть атрибутов какого-то реального человека, и он пытается по синтетическому набору выяснить неизвестные атрибуты. Например, зная возраст и город, можно ли подобрать запись в синтетических данных, чтобы угадать заболевание? Если алгоритм атаки (например, обученный классификатор или перебор) успешно угадывает скрытые поля лучше случайного, значит, синтетический набор **утечет корреляции** оригинала, позволяющие восстанавливать частную информацию. Низкая точность таких атак – индикатор хорошей приватности.

* **Атака по вхождению (Membership Inference Attack)** – проверяет, можно ли по синтетической модели определить, была ли определенная реальная запись в обучающем наборе. Атакующий генерирует ряд данных или использует доступ к модели, стремясь выяснить, реагирует ли генератор особым образом на известную запись. Если синтетическая модель выдаёт результаты, позволяющие с высокой долей уверенности сказать «эта запись была в обучении», то приватность нарушена. Формально, измеряют долю правильных определений при попытке отличить, какие реальные записи использовались при обучении генератора. Показатель близкий к 50% (случайному угадыванию) желателен, а существенно выше говорит о риске.

Кроме этих основных, есть и другие метрики: *разнообразие vs оригинальность* – например, количество синтетических записей, которые точно совпадают с любыми k записями оригинала ( ideally 0 совпадений). Метрики на основе дифференциальной приватности: если генератор был обучен с ε-дифференциальной приватностью, то можно теоретически гарантировать предел утечки информации, но ценой ухудшения fidelity.

Регуляторы и законы (о которых далее) особо отмечают: **даже полностью синтетические данные могут считаться персональными**, если сохраняется хоть какой-то способ реидентификации лица. Поэтому разработчики обязаны убедиться, что синтетический датасет не содержит записей или комбинаций, однозначно привязанных к конкретным людям. Совокупность перечисленных метрик – DCR, атаки по атрибутам и членству – в совокупности даёт оценку этого риска. Если все они в безопасных зонах (большой средний DCR, низкая успешность атак), можно заключить, что набор **обезличен надежно**. В противном случае, следует либо улучшать генеративную модель (например, добавить регуляризацию на разнообразие), либо применять пост-обработку (удалять подозрительно похожие на оригинал записи).

В итоге, качественные синтетические данные должны достигать баланса: **хорошо отражать оригинал (высокая fidelity), быть практически полезными (utility) и одновременно не нести угрозы приватности**. Часто повышение одного показателя снижает другой (например, слишком точное копирование повышает fidelity, но снижает privacy) – нахождение оптимума между ними является ключевой задачей при генерации синтетических наборов.

## Юридические и этические аспекты использования синтетических данных

Вместе с ростом интереса к синтетическим данным возникли вопросы: как они вписываются в существующие законы о защите информации и какие **этические моменты** следует учитывать при их применении? Рассмотрим правовое регулирование в разных регионах, а также общие принципы ответственного использования синтетических данных.

### Правовое регулирование (ЕС, США, Великобритания и др.)

**Европейский Союз (GDPR).** GDPR – один из самых строгих законов о персональных данных – формально регулирует только данные, относящиеся к идентифицированному или идентифицируемому лицу. Синтетические данные, *если они полностью анонимны*, могли бы выпадать из-под действия GDPR. Однако регуляторы ЕС занимают консервативную позицию: если исходные данные были персональными, предполагается, что и синтетические **считаются персональными**, пока не доказано обратное. Иными словами, на контролёре данных лежит обязанность убедиться, что риск реидентификации из синтетических данных сведен к минимуму – только тогда их можно считать анонимными и вывести из-под GDPR. В 2023–2024 гг. европейские надзорные органы (ICO в Британии, AEPD в Испании, Европейский надзор по защите данных – EDPS) начали исследования правового статуса синтетических данных. Они предупреждают: **не стоит автоматически считать синтетику анонимной**. Если синтетический набор позволяет выделить или узнать реального человека (directly or indirectly), он будет трактоваться как персональные данные со всеми вытекающими требованиями GDPR.

Отдельно следует упомянуть **проект Акта об ИИ (EU AI Act)**, продвигаемый в ЕС. В последней редакции (2023 г.) в Акте прямо упоминаются синтетические данные: например, для высокорисковых систем ИИ требуется обучение на качественных датасетах, и **Article 10** подчеркивает важность документирования и подготовки данных (в т.ч. синтетических). **Article 54** AI Act оговаривает, что в особых случаях (песочницы для ИИ в общественных интересах) могут использоваться реальные персональные данные, если **анонимизированных или синтетических недостаточно** для цели. Это косвенно признает: синтетические данные – желаемая альтернатива, но не всегда могут полностью заменить реальные. В целом, в ЕС синтетические данные рассматриваются как технология *повышения приватности*, однако подчеркивается необходимость оценки рисков реидентификации в каждом случае. Например, отчет PHG Foundation (Великобритания, 2023) советует проводить **Data Protection Impact Assessment** при решении использовать синтетические данные из исходно персональных наборов.

**США.** В Соединенных Штатах нет единого федерального закона, аналогичного GDPR, но действует несколько отраслевых и штатных нормативов. На уровне штатов: законы о приватности (CCPA в Калифорнии, VCDPA в Вирджинии, UCPA в Юте и др.) определяют персональную информацию схоже с GDPR. Примечательно, что **Юта (UCPA)** прямо вводит понятие *«синтетические данные»* – как данные, сгенерированные алгоритмами и *не содержащие персональных данных*. UCPA считает такие данные разновидностью «деидентифицированных», если они не могут быть разумно соотнесены с человеком и компания приняла меры не реидентифицировать их. Это первый случай прямого упоминания синтетических данных в законодательстве: по сути, закон признаёт их легитимный статус, при условии необратимости. В других штатах синтетика подпадает под исключения для агрегированных или деидентифицированных данных, которые освобождены от требований (как, например, в CCPA – *deidentified data* вне области действия, если соблюдены критерии необратимости).

В сфере здравоохранения США действует закон HIPAA, где в контексте обмена медицинскими данными рассматривается возможность использования синтетических пациентов вместо реальных. Министерство здравоохранения (HHS) пока не выпустило официальных правил о синтетических данных, но в исследованиях указывается: если синтетические медицинские записи генерируются таким образом, что ни один «пациент» не является реальным, то такие данные не считаются Protected Health Information. Однако, как и в случае с GDPR, ключевой момент – **отсутствие разумной возможности идентификации**.

**Великобритания.** После Brexit в Британии действует собственный UK GDPR, очень близкий по духу к европейскому. Управление Уполномоченного по информации (ICO) активно изучает тему синтетических данных. В проекте руководства по анонимизации (2022–2023) ICO упоминает синтетические данные как перспективный метод, но подчеркивает, что **нужно быть осторожным**: синтетика может оказаться *псевдо-анонимизацией*, если модель недостаточно разорвала связь с оригиналами. Пока что в британском законодательстве нет отдельных норм для синтетических данных – они попадают под общие правила. Тем не менее, Великобритания инвестирует в исследования PETs (технологий обеспечения приватности), куда входят и синтетические данные, признавая их роль в безопасном использовании данных.

**Другие юрисдикции.** В Канаде, Австралии, Сингапуре постепенно также выходят разъяснения. Общая тенденция: синтетические данные **не являются панацеей** для юридических рисков. Если они построены на персональных данных, то организация должна сохранять их под контролем и отвечать за них, как за обычные данные, пока не будет доказано, что синтез надежно анонизировал информацию. Такой *case-by-case* подход порождает пока некоторую неопределенность. Вероятно, со временем появятся стандарты оценки (например, методики сертификации того, что синтетический датасет удовлетворяет критериям анонимности). В научной среде уже предлагается считать **«безопасным» синтетическим набором** такой, где вероятность правильно угадать принадлежность записи реальному человеку не превышает определенный порог (связанный с дифференциальной приватностью). Возможно, эти идеи лягут в основу будущих нормативов.

### Этические аспекты

Даже при отсутствии прямых нарушений закона, с синтетическими данными связаны **этические вопросы**, которые важно учитывать организациям и исследователям:

* **Справедливость и отсутствие предвзятости.** Если реальные данные содержали **bias** (например, гендерный или расовый дисбаланс), то и синтетические, обученные на них, этот перекос унаследуют. Более того, генеративная модель может его даже усилить, особенно если малые группы представлены слабо. С этической точки зрения, просто заменить реальные данные синтетикой недостаточно – нужно анализировать и устранять заложенные несправедливости. С другой стороны, синтетические данные дают возможность *сознательно повысить справедливость*: можно сгенерировать дополнительную информацию для недопредставленных групп, добиваясь баланса. Например, в наборе для кредитного скоринга увеличить долю примеров заемщиков из меньшинств, чтобы модель обучилась нейтрально по отношению к расе. Этический долг разработчиков – внимательно относиться к таким вопросам и использовать синтетические данные как инструмент **снижения** дискриминации, а не ее скрытого продолжения.

* **Прозрачность и достоверность.** Возникает вопрос: должен ли тот, кто использует синтетические данные, сообщать об этом? В научных публикациях открытое раскрытие источника данных – часть стандарта воспроизводимости. Если исследование провели на синтетических данных, важно об этом заявить, чтобы другие понимали возможные ограничения результатов. Более того, есть мнение, что использование синтетических данных может **сказаться на воспроизводимости** исследований: внешний наблюдатель не сможет прямо проверить результаты, ведь он не имеет доступа к точно такому же синтетическому набору (каждая генерация может дать иной результат). Этически правильно – либо сохранять сгенерированный датасет и делать его доступным (если это возможно), либо описывать генеративный протокол настолько подробно, чтобы другие могли получить сопоставимый набор. В прикладных продуктах также стоит рассматривать прозрачность: например, если алгоритм обучен **не на реальных данных, а на синтетических**, нужно ли информировать об этом клиентов или регуляторов? Пока единых требований нет, но лучшей практикой считается честное раскрытие такой информации, особенно в чувствительных сферах (медицина, правосудие).

* **Ответственность за ошибки.** Синтетические данные могут содержать неправдоподобные или некорректные объекты (например, в сгенерированных медицинских записях может появиться комбинация симптомов, не встречающаяся в реальности). Если на основе таких данных обучена модель, которая ошибочно среагировала на несуществующий в реальной жизни паттерн, – кто несет ответственность? Этическая дилемма в том, что, вводя искусственные данные, мы вносим элемент вымысла в анализ. Поэтому рекомендуется привлекать **экспертов предметной области** к оценке синтетических данных. Например, пусть врачи просматривают выборку синтетических историй болезни на предмет реалистичности. Такой экспертный аудит поможет выявить нелепости и исправить генеративную модель (или отфильтровать данные). Ответственные разработчики должны отслеживать последствия применения синтетических данных: не приводит ли это к сбоям моделей, несправедливым решениям или иному негативному эффекту.

* **Злоупотребления и дезинформация.** Отдельно стоит упомянуть синтетические данные в виде медиа – сюда относятся **глубокие фейки** (изображения, видео, аудио, созданные нейросетью). Их использование несет серьезные этические риски, поскольку дает возможность правдоподобной дезинформации, клеветы, манипуляции общественным мнением. Хотя классический термин «синтетические данные» чаще применим к структурированным наборам для анализа, технология-то одна и та же. Соответственно, при генерации визуальных или аудио данных необходимо соблюдать этические нормы: маркировать синтетические медиа как таковые, не использовать их для обмана. Законодательно некоторые страны уже требуют указания, что контент создан ИИ. В научных и бизнес-кейсах важно убедиться, что синтетические изображения людей не нарушают ничьи права – предпочтительно генерировать их *с нуля*, а не дорабатывая фото реальных людей без разрешения.

Подводя итог, **юридическая и этическая «безопасность»** синтетических данных – не менее значимый аспект, чем техническое качество. Регуляции еще догоняют технологию: возможно, в ближайшие годы появятся более четкие правила. Но уже сейчас организациям рекомендуется подходить ответственно: проводить оценку рисков приватности, документировать процесс синтеза, получать информированное согласие (если нужно) на использование данных в генеративных моделях, и применять синтетические данные во благо – для улучшения доступности информации, а не во вред. Синтетические данные должны соблюсти тонкую грань между **полезностью для инноваций** и **соблюдением прав личности**. В руках ответственных специалистов эта технология способна существенно продвинуть исследование в медицине, сделать безопаснее обмен данными в финансах и ускорить развитие ИИ без угроз для человека.

## Примеры применения синтетических данных

Синтетические данные уже находят применение во многих отраслях, где традиционно есть проблемы с доступностью или конфиденциальностью данных. Рассмотрим несколько характерных примеров:

* **Медицина и здравоохранение.** Медицинские данные – крайне чувствительная сфера, защищенная законами (вроде HIPAA). Это затрудняет обмен информацией между больницами, исследователями и компаниями. Синтетические данные предлагают решение: можно сгенерировать искусственные истории болезни пациентов, сохранив статистические свойства реальных, и использовать их для анализа или обучения алгоритмов, не опасаясь раскрыть личные сведения. Так, модель *medGAN* была одной из первых, успешно синтезировавших электронные медицинские записи. В 2023 году появились диффузионные модели (TabDDPM-EHR, EHRDiff) для медицинских таблиц, которые создают **реалистичные записи пациентов** с различными диагнозами и лечениями. Исследования показали, что на таких данных можно обучать предиктивные модели (например, предсказание осложнений) практически без потери качества, а врачи-эксперты зачастую не отличают синтетические записи от реальных по правдоподобности. Компании, разрабатывающие ИИ для медицины, все чаще используют синтетические данные для предварительного обучения моделей, чтобы обойти дефицит размеченных медицинских наборов. При этом на регуляторном уровне (например, FDA в США) пока синтетические данные не могут полностью заменить клинические испытания, однако рассматриваются как полезный *дополнительный* инструмент. Например, для тренировки систем распознавания медицинских изображений (рентген, МРТ) создаются синтетические снимки органов с аномалиями – это повышает устойчивость алгоритмов к редким патологиям.

* **Финансы и банковское дело.** В финансовом секторе конфиденциальность клиентских данных – основной барьер для совместной работы и исследований. Банки не могут просто обмениваться базами транзакций или кредитных историй из-за угрозы утечки персональных и коммерческих тайн. Синтетические данные стали решением: ряд крупных банков в ЕС и США начали генерировать **полностью синтетические датасеты транзакций**, которые повторяют статистику реальных (распределение сумм, частоту операций, корреляции с демографией), но не соответствуют никаким конкретным клиентам. Такие наборы можно смело предоставлять аналитикам, стартапам для разработки fintech-решений. Инструменты вроде FinDiff, упомянутого ранее, помогают получать **высокодостоверные финансовые данные** для тестирования алгоритмов обнаружения мошенничества или стресс-тестирования моделей риска. Регуляторы тоже проявляют интерес: например, Банк Англии исследовал возможность публикации **синтетических банковских данных** вместо реальных статистик, чтобы повысить прозрачность рынка, не раскрывая конкретных участников. В сфере страхования – синтетические данные используются для моделирования редко происходящих событий (катастрофы, крупные страховые выплаты), позволяя актуариям и ML-моделям лучше готовиться к таким сценариям.

* **Автопилоты и транспорт.** Для обучения систем самоуправляемого вождения требуются миллионы километров данных – видео с дорог, показания лидаров, разнообразные дорожные ситуации. Собрать их вручную – дорого и долго, к тому же некоторые критические сценарии (например, перебегающий дорогу ребенок в ночное время) крайне редки. Поэтому разработчики автопилотов активно применяют **симуляторы и синтетические сцены**. Автоконцерны и компании типа Waymo, Tesla используют виртуальные полигоны: генерируют улицы, трафик, пешеходов и воспроизводят всевозможные кейсы, обучая ИИ реагировать на них. В 2023 году благодаря диффузионным моделям стало возможным улучшать графику симуляторов: берутся реальные дорожные кадры и с помощью текстовых подсказок модифицируются (добавить аварийную машину, изменить погоду). Это дает фотореалистичные изображения, на которых можно дообучать детекторы объектов, доводя их до требуемой надежности. Синтетические данные в авто тематике также используются для **внутрисалонных систем** – например, генерация различных положений пассажиров для алгоритмов безопасности (airbag deployment), синтетические голоса команд для голосовых ассистентов (во избежание сбора реальных записей водителей) и т.п. Можно сказать, что без синтетических данных прогресс автопилотов был бы значительно медленнее – они позволяют *безопасно* и *масштабно* тренировать ИИ на тех ситуациях, которые редко встретишь в реальной жизни, но которые критично отработать.

* **Маркетинг и ритейл.** В коммерции синтетические данные помогают поделиться инсайтами без раскрытия клиентской базы. Крупный ритейлер, например, может сгенерировать синтетический набор покупательских корзин, чтобы предоставить его партнерам для анализа потребительских предпочтений, не выдавая реальных покупателей. Также практикуется создание синтетических профилей клиентов для тестирования новых маркетинговых стратегий (digital twins). В e-commerce генерируются *фейковые заказы* с правдоподобными комбинациями товаров для нагрузочного тестирования систем и обучения рекомендательных алгоритмов, чтобы при запуске они не учились на пустом месте. Отдельное направление – **синтетические обзоры и отзывы**: LLM используются для создания множества вариантов отзывов на товар (позитивных, негативных, нейтральных), чтобы тренировать модели анализа тональности, учитывая богатство языка, которое бывает у реальных покупателей. Без таких данных модель, обученная только на официальных описаниях, может не понять сленг или сарказм в отзывах – синтетика восполняет пробел. Этически тут важно не перепутать – сгенерированные отзывы должны использоваться лишь для обучения моделей, но не как реальные отзывы на сайте (это было бы введением потребителей в заблуждение).

* **Государственный сектор и наука.** Органы статистики рассматривают синтетические данные как способ открывать данные для общественности. Например, статистическое ведомство может выпустить **синтетическую версию переписи населения**, которая позволяет исследователям проводить анализ, при этом никакой конкретный гражданин не присутствует в данных. Уже были пилотные проекты в США и Европе, где публиковались синтетические микроданные переписи и экономических опросов. В академических исследованиях, особенно социальных, это крайне полезно: можно изучать тренды, факторы и проверять гипотезы на богатом материале, не запрашивая доступ к конфиденциальным индивидуальным данным. Конечно, статистики тщательно проверяют такие наборы – чтобы синтетическая популяция сохраняла ключевые корреляции и распределения, и при этом не позволяла вычислить кого-либо конкретно. В Великобритании ONS (национальная статистическая служба) экспериментирует с *Secure Synthetic Data*, доступными исследователям как заменитель реальных сетов под GDPR.

Приведенные примеры далеко не исчерпывают всех областей применения. Синтетические данные также используются в образовании (создание учебных данных для задач машинного обучения, когда реальные собрать сложно), в кибербезопасности (генерация сетевого трафика для тестирования IDS-систем), в промышленности (синтетические сенсорные данные для тренировки систем обнаружения аномалий на оборудовании) и многих других сферах. Каждый год появляются новые кейсы – по мере того, как растет доверие к этой технологии и осведомленность о ее возможностях.

## Заключение

С 2023 по 2025 год область синтетических данных прошла путь от нишевого интереса специалистов по приватности до одного из центральных направлений развития ИИ и работы с данными. Современные подходы – от генеративных моделей вроде диффузионных и GAN до интеллектуальных LLM – позволяют создавать синтетические тексты, изображения и таблицы с беспрецедентным качеством и реализмом. Появление удобных инструментов (SDV, Diffusers, GPT-API и др.) сделало эту технологию доступной широкому кругу практиков.

Важным элементом стала разработка **метрик качества** и оценочных практик: больше нельзя довольствоваться визуальной похожестью или общей интуицией. Fidelity, utility, privacy – три кита, на которых держится доверие к синтетическим данным. Тщательная количественная оценка по каждому направлению уже стала стандартом де-факто. Это позволяет выявлять компромиссы и улучшать генеративные модели, делая синтетику одновременно полезной и безопасной.

Юридические и этические аспекты синтетических данных все еще в стадии формирования. Законодатели начинают признавать существование этой категории данных (как в случае Юты с UCPA) и интегрировать ее в правовые рамки. Однако на данный момент ответственность лежит на самих организациях: **осмотрительность и прозрачность** – залог того, что использование синтетических данных принесет благо. Соблюдение принципов privacy-by-design, учет возможных bias, информирование заинтересованных сторон о природе данных – все это должно входить в практику работы с синтетическими наборами.

Синтетические данные не являются панацеей или полной заменой реальным – скорей, это *ценный вспомогательный инструмент*. Они особенно незаменимы там, где реальные данные недоступны или чувствительны. Как мы увидели, во многих отраслях синтетика уже ускоряет прогресс: позволяет делиться информацией, защищая частную жизнь; учит ИИ новым навыкам, не дожидаясь накопления опыта в реальном мире; обеспечивает наличие данных там, где их катастрофически мало.

Перед сообществом стоят новые вызовы. Необходимо улучшать методы генерации, чтобы гарантировать отсутствие утечек (возможно, интегрируя дифференциальную приватность прямо в модели). Важна разработка стандартов сертификации синтетических данных – независимые проверки смогут повысить доверие. Также открытыми остаются вопросы восприятия: убедить конечных пользователей и регуляторов, что модель, обученная на синтетических данных, столь же надежна, – задача не только техническая, но и коммуникативная.

Тем не менее, тренд ясен: **synthetic data is here to stay**. По мере накопления успешных кейсов и развития технологий, синтетические данные становятся неотъемлемой частью ландшафта работы с данными. Они вписываются в концепцию *Data-Centric AI*, где фокус смещается на улучшение данных для улучшения моделей. В конечном счете, умелое применение синтетических данных способствует более **этичному, законопослушному и эффективному** использованию искусственного интеллекта и аналитики – когда мы можем извлекать знание и пользу, не вторгаясь в частную жизнь людей и не упираясь в ограничения реального мира. Это открывает захватывающие возможности для исследований и индустрии в ближайшие годы.

**Источники:**

1. The Tenyks Blogger. *Synthetic Data: Diffusion Models — NeurIPS 2023 Series*. (Medium, 31 Dec 2023).
2. Yingzhou Lu et al. *A Comprehensive Survey of Synthetic Tabular Data Generation*. (arXiv preprint 2504.16506, v2 May 2025).
3. Freshfields Bruckhaus Deringer. *Synthetic data: a privacy panacea?*. (Tech Quotient Blog, Nov 2024).
4. GA4GH Regulatory & Ethics Work Stream. *GDPR Brief: when are synthetic health data personal data?*. (GA4GH News, 11 Apr 2024).
5. Wu et al. *Reimagining Synthetic Tabular Data Generation through Data-Centric AI*. (NeurIPS 2023 Workshop).
6. David Berenstein et al. *Introducing the Synthetic Data Generator – Build Datasets with Natural Language*. (Hugging Face Blog, 16 Dec 2024).
7. Wikipedia. *Fréchet inception distance* (retrieved 2024) – описание метрики FID для оценки реалистичности изображений.
8. Stadler et al. *Synthetic data – anonymized or pseudonymized data?* (Datenschutz Notizen, 2023) – отмечает риск реидентификации из синтетических данных.
9. Islas Montero, Kazhdan. *Synthetic Data Generation for Scarce Road Scene Detection Scenarios* (NeurIPS 2023 Workshop) – применение диффузионной модели для автопилотов.
10. Li et al. *Synthetic Data Generation with LLMs for Text Classification: Potential and Limitations* (EMNLP 2023) – исследование эффективности GPT-3.5 для синтеза текстовых данных.
