# Рекомендательные системы: применение ИИ и ML

## Основы рекомендательных систем

Рекомендательная система – это программно-алгоритмический механизм, предлагающий пользователю **релевантные объекты** (товары, контент, услуги) на основе имеющихся данных о предпочтениях. Иначе говоря, такая система пытается предсказать, что именно может понравиться пользователю, исходя из информации о его поведении и (часто) поведении других пользователей. Рекомендатели помогают справиться с проблемой информационной перегрузки: вместо того, чтобы просматривать тысячи позиций, пользователь получает персонализированные подборки наиболее подходящих вариантов. В современной цифровой индустрии они повсеместны – от интернет-магазинов до соцсетей – и влияют на то, что мы покупаем, слушаем, смотрим и читаем.

**Типы рекомендательных систем.** Классически выделяют три основных подхода:

* **Коллаборативная фильтрация (Collaborative Filtering, CF):** формирует рекомендации на основе сходства *пользовательских предпочтений*. Предположение простое: если два пользователя в прошлом имели схожие оценки или выбор, то и в будущем вкусы у них будут совпадать. Например, если Иван и Мария ставили высоким рейтингом одни и те же фильмы, то фильмы, понравившиеся Марии, стоит предложить Ивану. Коллаборативные методы используют данные взаимодействия *«пользователь – объект»* (например, оценки, покупки, просмотры) множества людей. **Варианты CF:** память-ориентированные (memory-based) методы вычисляют сходство непосредственно по матрице пользователь-объект, а модельные (model-based) обучают модель на этой матрице. Коллаборативная фильтрация бывает **пользователь-пользовательной** (User-based CF) – ищем схожих пользователей, и **объект-объектной** (Item-based CF) – ищем похожие объекты. Так, Amazon сначала применял user-based CF, но затем перешёл к item-based для масштабируемости: вместо поиска похожих юзеров алгоритм подбирает товары, похожие на те, что уже просматривал покупатель. Коллаборативные системы эффективны, когда есть богатая история взаимодействий, но **страдают от проблемы холодного старта** – новому пользователю или новому товару нечего рекомендовать, пока не накопятся данные. Также им требуется много данных и активных пользователей, иначе матрица предпочтений слишком разрежена (sparsity) и трудно найти совпадения.

* **Контентная фильтрация (Content-Based):** основывается на *сходстве объектов по их содержанию* или атрибутам. Система знает характеристики каждого объекта (описание товара, жанр фильма, актеров и т.п.) и строит профиль интересов пользователя (например, ключевые слова, жанры, часто встречающиеся в понравившихся ему объектах). Затем рекомендуется новый контент, *похожий* на тот, что пользователь уже любил. Иными словами, content-based подход рассматривает рекомендацию как задачу классификации для каждого пользователя: на основе особенностей объектов, которые пользователь оценил положительно, обучается модель, отличающая «нравится» от «не нравится». Например, если читателю нравятся статьи про спорт, система будет показывать другие спортивные статьи. Преимущество – независимость от данных других пользователей, поэтому холодный старт по пользователям менее острый (можно рекомендовать что-то даже первому пользователю, исходя из контента объектов). Кроме того, такие рекомендации легко объяснить свойствами контента («этот фильм рекомендован, потому что в нём играет ваш любимый актёр»). Недостатки – ограниченность качеством и объемом описаний: система не увидит скрытых предпочтений, если они не отражены явно в фичах. Также есть склонность к **пересечению интересов (overspecialization)**: пользователь будет получать очень однотипный контент, и удивить или расширить горизонты контентному подходу сложно. Поэтому на практике часто комбинируют его с коллаборативным.

* **Гибридные методы (Hybrid):** объединяют несколько подходов, чтобы компенсировать недостатки каждого. Например, гибрид может параллельно генерировать рекомендации контентным и коллаборативным способом, а затем объединять результаты (через смешивание списков, усреднение оценок и др.). Возможен и более плотный гибрид: например, включать контентные признаки в модель коллаборативной фильтрации или наоборот – использовать предсказания CF как новые признаки для контентной модели. Грамотный гибрид может одновременно обеспечить новизну рекомендаций и решить проблему холодного старта (благодаря контенту), сохранив высокую точность за счёт учета коллективного опыта (CF). На практике большинство коммерческих систем – гибридные. Например, рекомендательный движок Netflix в разные годы представлял собой ансамбль из десятков алгоритмов: матричная факторизация, алгоритмы ближайших соседей, учет жанров и т.д., что позволило достичь высокой точности предсказания рейтингов.

**Основные задачи и сценарии применения.** Рекомендательные системы решают несколько тесно связанных задач:

* *Предсказание рейтингов* (rating prediction): по сути, регрессия, оценивающая, какую оценку (например, от 1 до 5) поставил бы пользователь тому или иному объекту. Исторически эта задача была популярна (знаменитый конкурс Netflix Prize по улучшению RMSE предсказания рейтингов фильмов), но на практике *ранжирование* оказалось важнее.

* *Формирование топ-N рекомендаций*: выдача списка из N лучших объектов для пользователя – наиболее распространенный сценарий. Здесь ключевой упор на правильный **ранжирующий алгоритм**, чтобы вверху списка оказались максимально релевантные для пользователя элементы. Метрики для этой задачи – precision\@N, recall\@N, NDCG и прочие (см. ниже раздел «Метрики»).

* *Поиск схожих объектов (item-to-item recommendations):* часто рассматривается как отдельная подзадача – например, на странице товара «Похожие товары» или «С этим также покупают». Это тоже рекомендация, но инициализируется конкретным объектом, а не пользователем. Обычно решается либо контентно (по атрибутам товара), либо через CF (товары, которые часто выбирали вместе с этим).

* *Сессионные и последовательные рекомендации:* в некоторых сервисах важно учитывать последовательность действий в рамках сессии (например, в музыке или видео автоматически подобрать следующий трек/ролик). Здесь задачи формулируются как *продолжение последовательности* (next-item prediction) с учетом порядка и времени. Используются специальные алгоритмы на последовательностях (см. RNN в разделе алгоритмов).

* *Контекстные рекомендации:* учитывают дополнительный контекст – время, локацию, устройство, текущие тренды и т.п. Например, днем в будни рекомендовать музыку, подходящую для работы, а вечером – для отдыха. Для этого часто применяются факторизационные машины или глубокие сети, способные обрабатывать контекстные признаки.

* *Многокритериальные и многоцелевые рекомендации:* когда нужно одновременно удовлетворять несколько критериев – например, максимизировать не только клики, но и разнообразие, или учитывать интересы сразу нескольких пользователей (семейный аккаунт, групповые рекомендации). Такие задачи относятся к **multi-objective** оптимизации, о ней подробнее в разделе про тренды.

## Алгоритмы и модели рекомендаций

Исторически в рекомендательных системах применялось множество алгоритмов – от простых эвристик до сложных нейросетей. Рассмотрим основные модели и их характеристики.

**Простые эвристики и нефильтрационные методы.** Прежде чем перейти к ML-подходам, стоит упомянуть самые базовые: *модели популярности* (слегка тривиальный алгоритм – рекомендовать всем самые популярные объекты) и *персонализированные подборки на основе фильтров по правилам* (например, подборки новинок жанра, который любит пользователь). Популярность часто служит бейзлайном: хотя она не персонализирована, в ряде случаев «топ-чарты» оказываются неплохими рекомендациями для новых или непрофилированных пользователей. Но всё же основная ценность рекомендателей – именно в персонализации посредством ML.

**Коллаборативные алгоритмы (memory-based).** Методы ближайших соседей – краеугольный камень классической коллаборативной фильтрации:

* **k-ближайших соседей (k-NN)**: для рекомендаций применяются в вариантах user-based и item-based CF. В *user-based k-NN* система находит k пользователей, наиболее похожих на данного (по историям оценок), и рекомендует ему объекты, популярные среди этих «соседей». В *item-based k-NN* – наоборот, для каждого объекта, которым интересовался пользователь, ищутся k похожих объектов, и набирается совокупность кандидатов. Затем объекты, встречающиеся чаще всего среди соседей (и с наибольшими весами сходства), рекомендуются пользователю. Сходство обычно измеряется косинусом между векторами оценок/просмотров или коэффициентом корреляции Пирсона. Алгоритм k-NN понятен и легко объясним («вы любите то же, что и эти похожие пользователи, поэтому вам понравится и то, что любят они»). Он **не требуeт сложного обучения** – достаточно вычислить метрику похожести. Однако на больших масштабах k-NN страдает: вычислительная сложность *O(M·N)* (M пользователей, N объектов) для сравнения всех со всеми может быть огромной. В практике e-commerce user-based эффективен, когда пользователей меньше, чем товаров, а item-based – когда товаров меньше (так было у Amazon). Новые данные учесть просто – обновить некоторое количество близостей, но *холодный старт* (новый пользователь/объект без соседей) – слабое место. Тем не менее, алгоритмы k-NN до сих пор используются как часть более сложных систем или для генерации кандидатов благодаря своей интерпретируемости.

* **Методы на основе кластеризации:** сходны с k-NN, но пытаются ускорить процесс, заранее объединив похожие сущности в кластеры. Например, сегментировать пользователей на группы по интересам и внутри группы рекомендовать наиболее популярные в ней объекты. Это снижает точность (группы усредняют предпочтения), но улучшает масштабируемость.

**Матричная факторизация и разложение матриц.** Это класс *model-based* подходов коллаборативной фильтрации, где алгоритм **обучается выделять скрытые факторы предпочтений**. Идея: большую разреженную матрицу «пользователи–объекты» можно аппроксимировать произведением двух матриц меньшей размерности (латентные факторы). Каждый пользователь и каждый объект представляются вектором в пространстве размерности *f* (например, f=50). Эти векторы обучиваются так, чтобы скалярное произведение (или другое свертка) вектора пользователя и объекта давало предсказываемую оценку или «интерес». Таким образом, модель сама выявляет скрытые характеристики: например, в музыке факторы могут приблизительно соответствовать жанрам, а в фильмах – сочетанию жанра, актёрского стиля, тематики и т.п., хотя факторы не обязательно интерпретируемы напрямую.

* **SVD (сингулярное разложение) и PCA:** классический способ факторизации – сингулярное разложение матрицы рейтингов, получающее ортогональные компоненты. Метод SVD из линейной алгебры может применяться напрямую, если матрица плотная. Однако в рекомендательных задачах матрица очень разрежена, поэтому SVD применяют с модификациями (например, заполняют пропуски средними, что может вносить шум). Более распространены алгоритмы *градиентного спуска* или *через чередующийся наименьший квадрат (ALS)*, решающие задачу минимизации ошибки восстановления известных рейтингов путем подбора векторов-факторов.

* **Алгоритм ALS (Alternating Least Squares):** итеративно оптимизирует матрицу факторов, поочередно фиксируя пользователей и вычисляя лучшие факторы для объектов, и наоборот. ALS удобен тем, что сводится к решению большого числа независимых задач линейной регрессии (least squares) – это хорошо распараллеливается. Например, платформа Spark MLlib предлагает ALS для рекомендаций. ALS устойчив к разреженности и хорошо масштабируется на средних данных (вплоть до десятков миллионов пользователь-объект взаимодействий) благодаря параллельности.

* **SGD (стохастический градиентный спуск):** альтернативный подход – задать функцию ошибки (например, RMSE между предсказанными и реальными рейтингами) и минимизировать ее стохастическим градиентом, поправляя латентные факторы. Этот метод был успешно применен победителями Netflix Prize (факторизационная модель сbias terms плюс SGD для обучения). Он лучше масштабируется на очень большие данные, чем классический SVD, и проще в реализации, чем ALS на распределенных данных. Минус – требует подобрать скорость обучения, может медленно сходиться.

Матричная факторизация стала **де-факто стандартом** для рекомендаций после 2006–2009 гг. благодаря Netflix Prize. Она значительно улучшала качество по сравнению с k-NN, так как умеет обобщать: даже если у двух пользователей нет общих оценок явно, их латентные профили могут быть близки. Также факторы позволяют естественно учесть имплицитную обратную связь: напр., использовать количество прослушиваний трека вместо бинарного факта. Практически, после вычисления факторных представлений, рекомендации можно выдавать очень быстро – достаточно умножить вектор пользователя на матрицу объектных факторов и выбрать топ-N. Это **обеспечивает real-time производительность** после оффлайн-тренировки. Недостатки факторизации: факторные признаки трудно объяснить пользователю (почему рекомендован тот или иной фильм – «потому что у него высокий фактор №7» неясно). Кроме того, холодный старт всё еще проблематичен – новая сущность не имеет факторов, пока кто-то не прореагирует на нее (эту проблему смягчает добавление bias – индивидуальных средних – и использование содержательных признаков, но об этом далее).

* *Расширения MF:* В практических задачах добавляют *бейасы* (сдвиги) для пользователей и объектов (учитывая, что у некоторых пользователей в среднем высокие оценки, а некоторые объекты в целом всем нравятся) – модель **SVD++** (Koren, 2008) учитывает явные и неявные предпочтения. Другие вариации включают регуляризацию (чтобы не переобучить факторы на шумных данных), учет времени (вкусы меняются) и т.д. MF-модели продолжают оставаться базовым компонентом многих современных решений, но часто обогащаются дополнительными признаками или нейросетевыми слоями.

**Факторизационные машины (FM).** Это обобщение идей MF на произвольные признаки. *Factorization Machines* (Steffen Rendle, 2010) – модель, которая способна обучаться на данных с любыми features (атрибуты пользователей, объектов, контекст) и автоматически моделирует все парные взаимодействия признаков как скалярные произведения латентных векторов. По сути, FM – это линейная модель + факторизованное представление для всех парных эффектов. Например, можно скормить модели one-hot ID пользователя, ID объекта, категорию объекта, признак «праздник/не праздник» и т.д. – FM научится, какие комбинации признаков влияют на отклик (интерес). Это мощно для **контекстно-ориентированных рекомендаций**: FM вобрала в себя идеи коллаб. фильтрации (через факторизацию ID-шников) и контентных методов (учитывая явные фичи). В особенности FM хорошо справляются с **проблемой холодного старта объектов**, если у новых объектов есть фичи (жанры, описание) – их можно включить, и модель будет оценивать новые объекты по комбинации этих атрибутов. FM обобщает MF и полиномиальную регрессию, умея моделировать второй порядок взаимодействий факторов. Преимущество – **гибкость и эффективность**: обучение FM почти как у линейной модели, сложность линейна от числа признаков, не экспоненциальна. Поэтому FM применялись в рекламных системах (где миллионы бинарных фич). Недостаток – FM по сути ограничена парными взаимодействиями; более высокоуровневые нелинейные сочетания требуют либо многофакторных расширений (Field-aware FM, High-order FM), либо перехода к нейросетям. Тем не менее, FM и их нейросетевые улучшения (Factorization Supported Neural Networks, DeepFM и др.) широко используются, особенно когда нужно объединить контентные и коллаборативные признаки.

**Нейросетевые подходы.** С развитием глубокого обучения рекомендательные системы тоже начали использовать нейросети для выявления сложных паттернов. Нейросети хорошо подходят для обработки разнообразных типов данных: текста описаний, изображений, последовательностей действий и т.п. Ниже – основные направления нейросетевых моделей в рекомендациях:

* **Многоуровневые перцептроны (DNN)** для общей коллаборативной фильтрации.  Изначально нейросети применяли как нелинейную замену матричной факторизации. Например, модель Neural Collaborative Filtering (X. He et al., 2017) предлагает заменить скалярное произведение в MF на произвольную функцию, аппроксимированную MLP. Пользователь и объект кодируются их embedding-векторами, затем объединяются (конкатенация или элементwise произведение) и пропускаются через несколько полносвязных слоёв, выдающих «оценку интереса». Такая сеть может теоретически выразить более сложные отношения, чем простая MF, хотя на практике требует больше данных для обучения. **Особенно выгоден DNN-подход**, когда можно добавить разные входы: помимо ID можно подать контентные признаки, признаки контекста (время, устройство) – сеть сама выучит необходимые весовые комбинации. Например, в продакшене YouTube использует двухступенчатую глубокую модель: первая сеть (candidate generation) – большая нейросеть, формирующая эмбеддинги пользователей и осуществляющая поиск кандидатов видео, вторая сеть (ranking) – уточняет порядок с помощью дополнительных фич и тоже реализована как нейросеть. DNN способны объединять **гетерогенную информацию** (история просмотров -> эмбеддинг пользователя; текст названия видео -> эмбеддинг видео; плюс явные фичи типа языка, страны и т.д.), а затем предсказывать вероятность заинтересованности. Пример: в модели Deep Learning Recommendation Model (DLRM) от Facebook используются эмбеддинги для категориальных фич (включая ID), которые потом проходят через несколько взаимодействующих MLP-блоков. В целом, MLP-подход в рекомендациях универсален: его минус – менее интерпретируем, чем MF, и требует тюнить архитектуру, но плюс – **высокая выразительность**, позволяющая повысить качество при большом объёме данных.

* **Автоэнкодеры**: Нейронные сети, обучающие **сжато представлять** предпочтения. Автоэнкодер может восстанавливать пользовательский вектор (строку в матрице рейтингов) через узкое скрытое представление – это аналог факторизации, но без явного ограничения ортогональности. DAE (denoising autoencoder) и VAE (вариационный) применялись для коллаборативной фильтрации (например, Mult-VAE для рекомендаций новостей). Они могут захватывать нелинейные особенности вкусов и устойчивы к шуму (DAE учат реконструировать при частично обнуленных входах). VAE даёт вероятностную интерпретацию: распределение над латентными факторами, что полезно для генеративных рекомендаций (см. ниже «генеративные подходы»).

* **Рекуррентные нейронные сети (RNN) и LSTM/GRU:** актуальны для **последовательных рекомендаций**. В отличие от статичных моделей, RNN обрабатывает *последовательность действий* пользователя (например, цепочку покупок или кликов) и пытается предсказать, что будет следующим. Это важно в медиа-сервисах (какой трек поставить следующим), новостях (что предложить прочитать сейчас исходя из свежепросмотренных статей) и e-commerce (какой товар может заинтересовать во время текущей сессии). Модель *Session-Based Recommendation with RNN (GRU4Rec)* показала, что GRU хорошо улавливает паттерны в сессиях даже без явных фич контента: например, последовательность просмотренных товаров в корзине. RNN позволяет учитывать **контекст порядка и времени**: то, что пользователь посмотрел сначала товар A, а потом B, может значить больше, чем просто факт просмотра. RNN обучается предсказывать следующее событие в последовательности (например, категорию следующего клика) – по сути, решает задачу ранжирования кандидатов с учетом истории как состояния hidden state. Достоинство – учитывается временная динамика, можно адаптироваться к *текущему состоянию* пользователя (недавние действия сильнее влияют на ближайшую рекомендацию). Недостаток – RNN сложно параллелить, и они хранят только скрытое состояние, которое может забывать давние интересы. Часто RNN-сети комбинируют с статичными эмбеддингами: например, Long-Term и Short-Term модель, где есть постоянный профиль и RNN, учитывающий последние действия.

* **Модели на базе внимания (Attention) и Transformers:** Современный тренд – применять механизм self-attention (как в трансформерах) для последовательных рекомендаций и не только. Пример – модель **SASRec** (Self-Attentive Sequential Recommendation), которая использует архитектуру трансформера для моделирования последовательности просмотров/прослушиваний: self-attention позволяет выявить, какие прошлые действия наиболее релевантны при предсказании следующего. В отличие от RNN, attention-модель может напрямую учесть **долгосрочные зависимости** (например, нынешний выбор товара может определяться тем, что пользователь смотрел неделю назад, минуя более свежие но нерелевантные события). Transformer-подходы (типа BERT4Rec – аналог BERT, предсказывающий пропущенные элементы истории) достигли state-of-the-art точности в ряде задач топ-N рекомендаций. Их плюсы: эффективно параллелятся на GPU, хорошо работают с длинными историями. Минусы: нужны большие данные для обучения, и inference (особенно полновесного трансформера) может быть тяжелым. Тем не менее, благодаря взрывному развитию NLP, трансформеры проникают и в рекомендации – иногда в гибридной роли (например, использовать предварительно обученный языковой модель для понимания текста запросов/описаний, а затем attention для совмещения с историей).

* **Графовые нейронные сети (GNN):** Многие рекомендательные задачи удобно представлять через графы. Например, имеем двудольный граф «пользователи–объекты» с рёбрами (интеракциями). Также бывают графы социальных связей пользователей, граф знаний о предметах (knowledge graph, связывающий объекты через общие атрибуты). GNN позволяют *распространять сигналы по графу*, извлекая информацию из многосвязных структур. В рекомендациях применяются графовые сверточные сети (GCN) для улучшения коллаб. фильтрации: например, модель PinSage (Pinterest, 2018) – графовая сеть, выделяющая эмбеддинги для узлов «пин» (картинка) на основе смежности в графе похожести и взаимодействий. GNN может агрегировать информацию о соседях: для товара – какие пользователи его смотрели и какие другие товары они смотрели, формируя более информативное представление, чем просто ID. Это позволяет улавливать *сложные связи*: например, «пользователь A смотрел X и Y; другой пользователь B тоже смотрел Y, значит через Y возникает связь A-B и можно рекомендовать A то, что посмотрел B». Обычная MF учитывает только 1-шаговые связи, а GNN – и дальше (двух-трёхшаговые пути). В социальной рекомендации GNN могут учитывать сеть друзей: например, получать эмбеддинг пользователя на основе его собственных взаимодействий + влияния друзей (neighbor aggregation). Результат – более точные рекомендации, особенно в условиях разреженных данных, когда прямых интеракций мало, но графовых путей много. Реализация GNN для больших графов – нетривиальна (нужны методы выборки соседей, усечение графа), но уже появились промышленные библиотеки (DGL, PyG) и примеры на индустриальных графах.

* **Генеративные модели и RL** – вынесем в отдельные пункты ниже (reinforcement learning, GAN), поскольку их использование имеет особую специфику.

**Таблица: Основные методы и их характеристики**

| **Метод**                      | **Принцип и тип**                                     | **Достоинства**                                                                                                                                                                   | **Недостатки**                                                                                                                                                                                                                       |
| ------------------------------ | ----------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **Модели k-NN (user/item)**    | Коллаборативный, память-ориентир.                     | Простота, интерпретируемость («похожие пользователи/товары»); обновление на лету                                                                                                  | Плохо масштабируется на большие данные; холодный старт, разреженность данных; учитывает только близких соседей, игнорируя остальное                                                                                                  |
| **Матричная факторизация**     | Коллаборативный, модельный                            | Выявляет скрытые факторы (обобщает предпочтения); компактное представление; быстрое выдача топ-N после обучения                                                                   | Требует обучения на исторических данных; факторы трудны для объяснения; новые пользователи/товары не имеют факторов без данных                                                                                                       |
| **Factorization Machines**     | Гибридный, модельный (факторы для любых фич)          | Учитывает контентные и контекстные признаки вместе с ID; решает некоторые cold-start за счет атрибутов; масштабируется для большого числа признаков                               | Ловит только взаимодействия 2-го порядка (линейно-нелинейные зависимости), может уступать глубоким моделям по качеству, если зависимость сложная                                                                                     |
| **Глубокая сеть (DNN, MLP)**   | Гибридный, модельный (нейросеть)                      | Очень гибкая: любые входные признаки (ID, контент, контекст); способна моделировать сложные нелинейности; достижение высоких метрик при большом объеме данных                     | Требует много данных и вычислений; архитектура – гиперпараметр (нужно настраивать слои, активации); менее интерпретируема, «черный ящик»                                                                                             |
| **RNN/seq2seq**                | Последовательная модель (RNN)                         | Учитывает порядок и время событий; хорошо для сессионных рекомендаций, может предсказывать «следующее» действие                                                                   | Трудности с долговременной памятью (могут забывать старые интересы); относительно медленные и сложные в обучении; неявная интерпретация результатов                                                                                  |
| **Attention/Transformer**      | Последоват. модель (Self-attention)                   | Улавливает дальние зависимости в истории; параллелизуется, дает SotA качество на длинных последовательностях                                                                      | Высокие требования к данным и ресурсам; модель может быть громоздкой для продакшена, нужны сокращенные версии; требует настройки позиций, масок и пр. для правильной работы                                                          |
| **Graph Neural Network (GNN)** | Графовая модель (GCF, соц.граф)                       | Учитывает структуру связей и пути на графе; улучшает рекомендации при разреженных данных, используя опосредованные связи; применима для соц. связей и знаниевых графов            | Реализация и масштабирование сложнее (графовые вычисления); трудно объяснить результат (учитываются сложные пути); требовательна к памяти (хранение эмбеддингов для узлов)                                                           |
| **Контентная фильтрация**      | Контентный, модельный (профиль + сходство)            | Работает без данных других пользователей (индивидуально); решает cold-start для новых объектов за счет атрибутов; легко объяснить причину рекомендации (общие черты контента)     | Ограничена качеством контента (если описание скудное – плохо рекомендует); склонна к узкой специализации (не предлагает ничего вне зоны текущих интересов); новые пользователи без истории все равно проблема                        |
| **Гибридные системы**          | Комбинация (смешивание, ансамбль)                     | Объединяют лучшие стороны методов, повышая качество; смягчают cold-start и проблему разнообразия; гибкость – можно настроить баланс разных алгоритмов                             | Сложность реализации (несколько моделей вместо одной); трудность в поддержке и настройке весов комбинирования; возможны противоречия между методов, требующие особой логики разрешения                                               |
| **Многошаговые (каскадные)**   | Архитектурный подход (candidate generation + ranking) | Высокая эффективность: быстрая генерация кандидатов (модель попроще) и тщательный ранжирующий этап (модель посложнее); позволяет масштабировать рекомендацию на огромные каталоги | Реализация двух (или более) моделей; потенциально сложность в совместной оптимизации (каждый этап оптимизируется по своим целям); кандидаты ограничивают recall – если на первом этапе потерян хороший объект, далее уже не появится |

| **Метод**                    | **Пример использования**                                                                                                                                                           |
| ---------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| k-NN соседей                 | «Пользователи, похожие на вас, купили…» (интернет-магазин); «похожие треки» (музыка)                                                                                               |
| Матричная факторизация       | Рекомендации фильмов на основе оценок (киносервис); персонализация товаров (маркетплейс)                                                                                           |
| Factorization Machines       | Контекстные рекомендации (например, учитывая время суток, устройство); реклама с таргетингом на пользовательские и товарные фичи                                                   |
| DNN (MLP)                    | Алгоритм рекомендаций YouTube (эмбеддинги + глубокий ранкер); модель ранжирования ленты соцсети (учитывает десятки признаков взаимодействия)                                       |
| RNN (последовательный)       | Рекомендация следующего трека/видео на основе только что прослушанных; рекомендации товаров в реальном времени во время сессии покупателя                                          |
| Transformer (self-attention) | Персональный плейлист на основе истории прослушиваний за год (учет дальних связей); модель типа BERT4Rec для предсказания, какие фильмы пользователь пропустил из ранее интересных |
| GNN (графовая)               | Рекомендации друзей в соцсети (учет графа дружбы); рекомендации продуктов с учетом графа знаний (связи между продуктами по характеристикам)                                        |
| Content-based                | Рекомендации новостей по тематическому профилю читателя; совет песен на стриминге по схожести с любимыми исполнителями                                                             |
| Hybrid                       | Netflix: сочетание коллаб. фильтрации по оценкам + контент по жанрам + бизнес-правила; e-commerce: сначала контентные для новых товаров, затем CF для устоявшихся                  |
| Multi-stage pipeline         | YouTube/Netflix: первая модель быстро отбирает несколько сотен кандидатов из каталога, вторая – тщательно ранжирует топ-10 для показа                                              |

**Методы на основе усиленного обучения (Reinforcement Learning, RL).** Традиционно рекоммендеры воспринимали как задачу предсказания в статической среде: есть фиксированная история, по ней рекомендуем. Но в реальности система взаимодействует с пользователем *непрерывно*, получая отклик (кликнул/не кликнул, смотрел долго или сразу закрыл и т.п.). Это можно трактовать как задачу *обучения с подкреплением*: агент (рекомендатель) в каждый момент выбирает действие (набор рекомендаций), получает вознаграждение (например, пользователь посмотрел видео до конца) и обновляет политику. RL-подход полезен, когда надо оптимизировать **долгосрочное взаимодействие**. Например, иногда выгоднее порекомендовать не самый популярный сейчас объект, а что-то разнообразящее, чтобы повысить удовлетворенность пользователя в перспективе. Или в новостях – чередовать темы, чтобы не было пресыщения. RL позволяет формализовать *exploration vs. exploitation* (баланс между показом уже любимого контента и исследованием новых интересов). В новостных платформах применяют алгоритмы *многорукого бандита* – упрощенный RL, где нет длинной последовательности, но учитывается неопределенность: можно постепенно смещать трафик к новому алгоритму, если он показывает лучшие CTR, используя, например, жадный алгоритм Эпсилон или Томпсон-семплирование для A/B тестирования различных рекомендательных стратегий.

В академических работах есть примеры полного RL: например, использование Q-Learning/DQN для выбора целого списка рекомендаций (так называемый *slate recommendation problem*). Компания Netflix исследовала подходы, где цель – максимизировать время, проведенное на платформе за месяц, а не только клик немедленно. Такие задачи приводят к большим состояниям и экшенам, поэтому RL в рекомендациях пока сложен. Чаще применяются *модели имитации RL*: например, генерировать последовательности рекомендаций с помощью policy-gradient методов на симулированных данных. Фреймворк RecSim (Google) позволяет исследовать алгоритмы RL для рекомендателей, симулируя пользователей.

В индустрии более приземленный подход – *контекстуальные бандиты*: система как бы проводит непрерывный эксперимент, немного рандомизируя выдачу и обучаясь на результатах, подстраивая модель в режиме онлайн. Например, если новостной сервис видит, что пользователь редко кликает статьи из спорта, он снизит их вероятность показа.

**Вывод:** алгоритмов для рекомендательных систем очень много, и на практике часто используют ансамбли: например, *градиентный бустинг решающих деревьев* для предсказания вероятности клика, в который входят фичи, сгенерированные коллаборативными моделями (эмбеддинги, счетчики) и контентными анализаторами (текстовые представления описаний и т.д.). Далее мы обсудим, как эти алгоритмы внедряются и оцениваются.

## Инфраструктура и инженерия рекомендательных систем

Разработать хороший алгоритм мало – нужно ещё суметь его обучить на больших данных и быстро выдавать рекомендации пользователям. Инфраструктура рекомендательной системы охватывает сбор данных, построение пайплайна обучения и развертывание модели в продакшене, а также постоянную проверку качества (онлайн-эксперименты). Рассмотрим ключевые аспекты.

**Сбор и обработка данных.** Данные – топливо рекомендаций. Как правило, используются следующие источники:

* Логи явных реакций пользователей: оценки (звёздочки, лайки/дизлайки), отзывы.
* Логи неявных реакций: просмотры, клики, время просмотра/чтения, покупки, добавление в корзину, пропуск песни, добавление в избранное и т.д. **Имплицитная обратная связь** (implicit feedback) зачастую более доступна и массовая, чем явная – например, Netflix имеет много данных о том, что смотрят, и мало – о том, что ставят лайк.
* Профильные данные пользователей: демография, местоположение, языковые предпочтения, ранее заявленные интересы.
* Данные об объектах: описание товара, жанр фильма, технические параметры, цена, изображения, иерархия категорий.
* Социальные графы, если релевантно (список друзей, подписки).
* Внешние данные: календарь (праздники), тренды (какие статьи сейчас популярны глобально), даже погода (для рекомендаций, скажем, фильмов под дождливую погоду).

Перед использованием данные очищаются (от дубликатов, спама), агрегируются (например, подсчитать количество прослушиваний каждой песни каждым пользователем) и превращаются в удобный формат (разреженная матрица, список взаимодействий, тензоры для модели). Обычно формируют обучающую выборку – пары (user, item, \[context]) -> оценка/факт взаимодействия. При неявной обратной связи распространена техника sampled negatives: для известных положительных взаимодействий добавляют примеры «пользователь не выбрал объект X» как отрицательные (либо случайно, либо по некоторому правилу).

**Разделение на оффлайн и онлайн этапы.** Большинство систем строятся так: *оффлайн-компонент* периодически обучает модель (например, раз в день пересчитывает факторы MF или обучает нейросеть на обновленных данных), а *онлайн-компонент* отвечает на запросы пользователей в реальном времени, используя предобученную модель. Это связано с тем, что обучение может быть долгим (часы на больших данных), а рекомендации нужно выдавать за миллисекунды. Например, для матричной факторизации вычисляют матрицы эмбеддингов оффлайн и сохраняют. Онлайн при заходе пользователя подтягивается его вектор и быстро умножается на матрицу предметов – это очень быстро на современном оборудовании. Для k-NN – оффлайн считают таблицы похожести топ-N для каждого товара, а онлайн просто смотрят в предсчитанный список. Нейросетевые модели могут оффлайн обучаться, а онлайн выполняться (inference) на GPU/CPU в сервиса, причём часто с ускорением (могут храниться эмбеддинги и только небольшой мульти-лейер применять онлайн).

**Архитектура многослойной выдачи.** В промышленных системах часто используется *многоступенчатый pipeline рекомендаций*. Типичная схема – **двухэтапная выдача**: (1) **Candidate Generation (генерация кандидатов)** – быстрое получение нескольких сотен потенциально интересных объектов из всего каталога; (2) **Ranking (ранжирование)** – тщательная сортировка этих кандидатов по предсказанной степени интереса пользователю. Например, на YouTube из миллионов видео сначала отбираются несколько сотен кандидатов с помощью облегченной модели (часто – простой MF или небольшая нейросеть) – она работает быстро. Затем более тяжелая модель ранжирует эти сотни, учитывая множество факторов (история, текстовые фичи, актуальность по времени и др.), и в топ выходят 10-20 видеороликов для показа. Такая *воронкообразная архитектура (funnel)* позволяет масштабировать рекомендацию: первая стадия – широкая и быстрая, вторая – узкая но глубокая по анализу. Иногда добавляют и третий этап – **re-ranking**, когда итоговый список ещё слегка перестраивается по бизнес-правилам (например, чтобы не было 5 очень похожих товаров подряд, добавляется диверсификация). Также может быть этап **постфильтрации** – убрать из рекомендаций то, что пользователь уже купил, или нежелательный контент.

Важный элемент инфраструктуры – эффективные **поисковые индексы** для быстрого поиска по эмбеддингам. Например, если у нас есть эмбеддинг пользователя, сформированный нейросетью, и мы хотим найти top-N ближайших векторов товаров, мы не можем линейно пробежать по миллиону товаров (это было бы медленно). Применяются алгоритмы *приближенного ближайшего соседа* (ANN search) – библиотеки типа Facebook FAISS, Spotify Annoy, сконфигурированные под быстрое нахождение ближайших векторов в пространстве. Такие индексы строятся оффлайн (c определенной точностью) и позволяют за десятки миллисекунд извлечь кандидатов для каждого пользователя.

**Масштабируемость и задержки.** Latency (задержка ответа) – критический параметр. Пользователь не станет ждать даже секунды, пока система думает над рекомендациями – все должно происходить мгновенно, особенно в реальном времени (пример: пользователь скроллит ленту, и система должна за миллисекунды ранжировать новый кусок контента). Поэтому инженерные решения включают:

* Кеширование (caching): предварительная заготовка рекомендаций. Например, ночью расчитать для каждого пользователя ежедневный список топ-контента. Это снижает персонализацию по последним действиям, но можно обновлять кеш по триггерам (пользователь сделал что-то важное – пересчитать для него).
* Приоритет в вычислениях: ранжирующая модель может запускаться с ограничением времени, чтобы вернуть хоть что-то. Также распределяют нагрузку – тяжелые модели на GPU с очередями запросов.
* Горизонтальное масштабирование: разнос компонентов на разные серверы – сервис генерации кандидатов, сервис ранжирования, база данных фич. Ключ – **поддержание скоростного потока данных** между ними. Часто хранят предварительно вычисленные профили пользователей и атрибуты объектов в быстрой NoSQL памяти, чтобы сервису ранжирования не ходить в медленные хранилища.
* Технологии big data для обучения: чтобы переварить терабайты логов, используют Hadoop/Spark для подготовки данных, распределенное обучение (например, Parameter Server архитектура для нейросетей или Horovod для распределенного SGD). Многие крупные компании создают специальные платформы ML (Uber Michelangelo, Alibaba Pai), которые упрощают весь цикл – от данных до деплоя модели.

**A/B тестирование и мониторинг.** После разработки новой модели ее качество проверяют не только оффлайн (метрики типа precision\@k на отложенных данных), но и **онлайн**, то есть на настоящих пользователях. Делается это через контролируемый эксперимент: небольшому проценту аудитории (например, 5%) начинают показывать рекомендации по новому алгоритму, остальным – по старому, и сравнивают ключевые бизнес-метрики: клики, время на сайте, конверсии в покупку, удержание пользователей и т.д. Такой тест называется A/B тестирование. Он важен, потому что улучшение оффлайн метрик не всегда означает улучшение реального UX (пользовательского опыта). Например, более агрессивные рекомендации могут повысить кликабельность (CTR) краткосрочно, но пользователи быстрее устанут (долгосрочное удержание снизится). Только наблюдая за *обеими когортами* (A – контроль, B – новая система) достаточно долго, можно сделать надежный вывод. Компании как Amazon и Netflix имеют целую инфраструктуру для А/Б тестов (например, Amazon Weblab) и запускают десятки экспериментов одновременно.

Кроме экспериментов, важен постоянный **мониторинг** работы рекомендателя: отслеживать время ответа (нет ли деградации), процент ошибок, и метрики качества в онлайне. Последнее – сложнее, но возможно: например, средний рейтинг рекомендуемых товаров (пользователи могут ставить оценки), или раз в месяц опросы удовлетворенности. Если показатели падают, система должна сигнализировать, что нужна внимание команды (может, изменился поток данных, или модель устарела и требует обновления).

Наконец, инфраструктура включает обеспечение **приватности и безопасности данных**. Рекомендательная система оперирует персональными данными – поэтому хранилища логов должны быть защищены, идентификаторы – анонимизированы. После инцидента с Netflix Prize, когда по анонимным данным рейтингов удалось деанонимизировать некоторых пользователей, компании стали внимательнее. В наше время внедряются технологии: *Differential Privacy* – добавление шума, гарантирующего невозможность выяснить предпочтения конкретного человека из суммарных данных; *Federated Learning* – обучение моделей на устройствах пользователей без выгрузки сырых данных (пока применяется в основном для мобильных клавиатур, но в будущем, возможно, и для рекомендаций); ограничения на сбор данных согласно законам (GDPR в Европе дает пользователям право знать, какие данные собираются, и требовать их удаления). Эти аспекты мы подробнее рассмотрим в следующем разделе.

## Метрики оценки качества рекомендаций

Для автоматической оценки, насколько хорошо рекомендательная система выполняет свою задачу, используют различные **метрики качества**. Метрики делятся на **точностные (accuracy)** – измеряют, насколько рекомендации совпадают с истинными предпочтениями, и **дополнительные (разнообразие, новизна, покрытие)** – оценивают свойства списков рекомендаций, выходящие за рамки одной точности.

**Классические accuracy-метрики:**

* **Precision\@K (точность на K):** доля рекомендованных объектов в топ-K, которые оказались релевантны пользователю. «Релевантны» обычно значит – пользователь их действительно оценил положительно или выбрал (например, в тестовых данных видно, что среди 10 рекомендованных фильмов 4 пользователь уже смотрел и любил, значит Precision\@10 = 0.4). Высокая precision\@K означает, что система практически не советует лишнего.

* **Recall\@K (полнота на K)** – доля всех релевантных объектов для пользователя, которые попали в рекомендацию топ-K. Например, из 20 фильмов, которые пользователю понравились за год, система порекомендовала 5 – recall = 5/20 = 0.25. Recall показывает, насколько система умеет покрывать все интересы пользователя. Часто используют синоним **Hit Rate\@K** – вероятность, что среди K рекомендаций найдется хотя бы один действительно интересный объект (в некоторых работах hit rate приравнивают к recall, в других – буквально «факт попадания хотя бы одной релевантной»).

* **F1\@K:** гармоническое среднее precision\@K и recall\@K. Может использоваться единая метрика баланса точности и полноты.

* **MRR (Mean Reciprocal Rank):** метрика для ранжирования: Reciprocal Rank для пользователя = 1/(позиция первого релевантного объекта), а MRR – среднее по всем пользователям. Она увеличивается, если релевантные объекты встречаются ближе к вершине списка рекомендаций.

* **MAP (Mean Average Precision):** средняя точность по всем релевантным объектам. Считается так: для одного пользователя вычисляется Average Precision – усреднение precision\@ranks для каждой релевантной позиции в рекомендациях. Затем усредняют по всем пользователям. MAP учитывает и процент релевантных, и их позиции в списке (чем выше в списке находятся релевантные – тем выше MAP).

* **NDCG (Normalized Discounted Cumulative Gain):** популярная метрика ранжирования, учитывающая *градуированную релевантность* (например, у нас есть рейтинги 1–5 звезд как степень удовлетворенности) и позицию. DCG вычисляется как сумма релевантностей с понижающим коэффициентом для нижних позиций (например, релевантность делят на логарифм позиции). Затем DCG нормируется на *идеальный DCG* (сортировку по убыванию релевантности) – получается NDCG от 0 до 1. NDCG\@K очень распространена на соревнованиях, т.к. отражает, что рекомендовать два любимых фильма на 1-м и 2-м месте лучше, чем на 2-м и 10-м. Недостаток: nDCG не штрафует за лишние нерелевантные рекомендации, если все релевантные уже наверху, поэтому её иногда дополняют другими метриками.

* **AUC (Area Under ROC Curve):** если задача формулируется как бинарная классификация «интересен/не интересен», можно использовать AUC для оценки способности алгоритма различать релевантные объекты от нерелевантных. AUC удобна для implicit данных (когда явных негативов нет, но можно считать все невыбранные объекты негативами) и для алгоритмов, выдающих непрерывный скор. AUC = 0.5 эквивалентно случайному ранжированию, 1.0 – идеальное ранжирование.

Какие метрики выбрать, зависит от целей. В e-commerce чаще важна **precision\@K** (показывать только действительно интересные товары, чтобы не раздражать лишним), а в контентных платформах – **recall** (не пропустить что-то, что пользователь точно хотел бы). NDCG и MAP – сбалансированные метрики общего ранжирования.

**Пример расчета:** допустим, система рекомендовала 5 товаров, из них пользователь купил 2. Кроме того, у пользователя в тестовом наборе было всего 4 товара, которые он купил из интереса. Тогда Precision\@5 = 2/5 = 0.4, Recall\@5 = 2/4 = 0.5. Если эти 2 купленных товара стояли на 1 и 3 месте списка, то MRR = (1/1 + 1/3)/2 = \~0.83 (если считать для многих пользователей, усредним). AP для этого пользователя = (1/1 + 2/3) / 2 = \~0.83, MAP – среднее по всем. NDCG\@5 можно посчитать, присвоив купленным товарам релевантность 1, остальным 0: DCG = 1/log2(1+1) + 0/log2(2) + 1/log2(3+1) + ...; IDCG для 2 релевантных = 1/log2(1+1)+1/log2(2+1); отношение даст значение.

При оффлайн оценке на датасете часто смотрят сразу несколько метрик, например: HitRate\@10, NDCG\@10. Метрики также можно усреднять по пользователям или по рекомендациям – обычно усредняют по пользователям (чтобы каждый пользователь внес равный вклад, а не перегруженные данными пользователи доминировали).

**Другие важные показатели качества:**

* **Coverage (покрытие):** доля элементов каталога, которые когда-либо рекомендованы пользователям. Если система рекомендует из всего миллиона товаров только тысячу, то покрытие = 0.1%. Узкое покрытие плохо, потому что означает, что многие объекты никогда не будут показаны, даже если есть своя аудитория. Хочется, чтобы рекомендатель умел находить нишевые объекты для тех, кому они подходят. Поэтому увеличивают покрытие, вводя diversity или эксплоринг. Coverage можно считать и на уровне пользователей (сколько % подходящих товаров система находит) – это близко к recall.

* **Novelty (новизна):** насколько рекомендуемые объекты новые или неизвестные пользователю. Это важно, чтобы рекомендации не были скучными (не рекомендовать то, что пользователь и так знает). Новизну измеряют косвенно: например, средняя популярность рекомендуемых объектов (меньше – новее, т.к. вероятно пользователь не сталкивался); или доля рекомендаций, которых нет в истории пользователя. Более формально – *серендипность (serendipity)*: процент рекомендаций, которые пользователь не только не знал, но и оказался приятно удивлен. Серендипность трудно измерить автоматически, часто это предмет пользовательских опросов.

* **Diversity (разнообразие):** разнообразие внутри списка рекомендаций. Например, если среди топ-10 фильмов все – комедии с одним и тем же актером, то список однородный. Разнообразие можно измерить как среднее попарное несходство рекомендованных объектов (по жанрам, описаниям). Высокое разнообразие гарантирует, что система покрывает разные интересы пользователя. Однако слишком высокое может снизить удовлетворение (половина не по душе). Поэтому diversity обычно рассматривают во взаимосвязи с precision: часто оптимизируют **метрику типа α-nDCG**, где вводится штраф за однородные рекомендации.

* **Calibration (калибровка):** насколько структура рекомендаций соответствует профилю пользователя. Например, если пользователь слушает 70% рока и 30% джаза, а рекомендации – 100% рок, то они не откалиброваны относительно вкуса. Есть метрики, сравнивающие распределение жанров/категорий в истории и в списке рекомендаций.

* **Fairness metrics:** специфические для оценки справедливости (о них в следующем разделе). Пример – Disparate Impact: насколько доля определенной категории (например, фильмы женских режиссеров) в рекомендациях соответствует их доле в каталоге или соответствует нейтральному ожиданию, без перекосов.

В оффлайн экспериментах обычно основное внимание уделяют precision/recall/NDCG. Но в реальных условиях конечная цель – **бизнес-метрики** и **удовлетворенность пользователей**. Например, Netflix оптимизирует часы просмотра и удержание подписчиков, интернет-магазин – конверсию и средний чек, новостной сайт – количество прочитанных статей и длительность сессии. Эти показатели не всегда напрямую коррелируют с чисто точностными метриками ML. Поэтому часто делают так: отбирают несколько моделей по высоким оффлайн-метрикам, а затем проверяют их на реальных пользователях (через A/B тест) по бизнес-показателям. В случае расхождения – возможно, выбранная метрика не полностью отражает цель. Так, чтобы увеличить «вовлеченность» (time spent), система может жертвовать точностью и предлагать иногда что-то неожиданное.

**Пример компромисса:** новости. Если показывать только то, что с максимальной вероятностью кликнут (оптимизация precision\@1), то алгоритм может в погоне за кликом выдавать очень «кликабельный» но однообразный или низкокачественный контент. Это увеличит CTR краткосрочно, но снизит доверие к платформе в долгосрочной перспективе. Поэтому в метрики иногда прямо включают понятия вроде *доверие*, *качество* – но это сложно формализовать. Вместо этого определяют proxy-метрики: время чтения (если долго читает, значит интересно по-настоящему), процент вернувшихся на следующий день пользователей, и оптимизируют уже комбинацию показателей.

Таким образом, метрики – **многогранный инструмент**. Правильный выбор и баланс метрик – часть задачи: нужно и удовлетворять индивидуальные потребности пользователя (high precision), и открывать новое (новизна, recall), и поддерживать бизнес-цели (конверсии, доход). Именно поэтому современные системы внедряют **multi-objective optimization** (см. раздел трендов) – стремление формально учесть несколько целей при обучении модели или при ранжировании.

## Этические и пользовательские аспекты

Рекомендательные системы сильно влияют на то, с каким контентом взаимодействуют люди, поэтому встают вопросы этики, ответственности и влияния на пользователей. Рассмотрим главные из них:

**Эффект фильтров и “filter bubble”**. Термин *«фильтр-баббл»* (filter bubble, информационный пузырь) описывает ситуацию, когда персонализация приводит к **изоляции пользователя в коконе из однотипной информации**. Алгоритм, подстраиваясь под вкусы, начинает показывать все более узкий спектр контента, который подтверждает уже имеющиеся взгляды пользователя. В результате человек может не видеть альтернативных мнений, новых жанров – снижается разнообразие потребляемой информации. Классический пример – ленты соцсетей и новости: пользователь кликает только определенные темы или политические взгляды, и система в погоне за engagement будет выдавать ему *только* такие новости, усиливая его убеждения (так называемый **echo chamber**, эффект эхо-камеры). Это чревато поляризацией взглядов, радикализацией, или просто упущенными возможностями узнать что-то новое.

Рекомендательные системы невольно могут **усилить популярные вкусы** и скрыть непопулярные: если алгоритм чаще показывает то, что и так популярно, менее известный контент становится еще незаметнее (эффект Матфея). Исследования пытаются выяснить, насколько реальны filter bubbles: одни работы подтверждают наличие эффекта (особенно при длительном использовании), другие отмечают, что пользователи всё же периодически выходят за рамки рекомендаций самостоятельно. Тем не менее, осознание проблемы привело к методам борьбы:

* Включение в рекомендации элемента **разнообразия** – намеренное расширение жанров, случайная подмешка контента, не полностью соответствующего прошлому профилю. Это может «проколоть пузырь», предложив что-то непривычное.
* **Регулируемая персонализация:** некоторым платформам предлагается дать пользователю больше контроля – например, ползунок «показывать более разнообразный контент» или возможность отключить персонализацию. Так пользователь сам решит, хочет он узкую подборку или широкий обзор.
* **Прозрачность и объяснимость:** если система объясняет, почему предлагает тот или иной материал («потому что вы читали много новостей на тему X»), пользователь может осознать свой «пузырь» и решить поискать вне его.

Отдельно, законодатели задумываются обязать крупные платформы раскрыть возможность *chronological feed* (неперсонализированная лента) – например, в некоторых странах соцсети должны иметь опцию показа постов просто по времени. Это ответ на опасения, что алгоритмы слишком ограничивают кругозор пользователей.

**Справедливость (Fairness) и отсутствие предвзятости.** Алгоритмическая несправедливость – серьезная тема в ML, и в рекомендательных системах тоже. Система считается **небеспристрастной**, если её рекомендации систематически ухудшают положение какой-то группы людей или, наоборот, продвигают одни группы сильнее других по причинам, не связанным с качеством контента. Примеры проблем:

* Гендерный или расовый перекос: например, рекомендательная лента видео может чаще показывать контент от авторов определенной расы, уменьшая видимость авторов другой расы, если исторические данные были смещены. Или сервис вакансий мог бы начинать рекомендовать высокооплачиваемые должности в tech больше мужчинам, чем женщинам, если обучен на данных, где мужчин в IT больше – **усиливая существующий дисбаланс**.
* “Popularity bias” – предвзятость к популярному: алгоритм рекомендует новичкам только наиболее популярные треки, тем самым новым или нишевым исполнителям сложно пробиться – несправедливость по отношению к контент-создателям.
* **Fairness для пользователей:** система может показывать разным пользователям контент разного качества. Например, сервис может реже рекомендовать дорогие премиум-товары определенной категории покупателей, считая, что они их не купят – потенциально *дискриминация* по экономическому признаку.

В контексте fairness важно определить, для кого должна быть справедливой система: для пользователей (каждый пользователь получает равный уровень услуги?), для производителей контента (каждый артист/продавец имеет шанс быть увиденным?), или для обоих (multi-stakeholder fairness). Определения fairness разные:

* **Individual fairness:** похожим пользователям – похожие рекомендации. Никто не должен необъяснимо получать хуже контент, чем другой с аналогичными интересами.
* **Group fairness:** группы (по полу, возрасту, этносу и т.п.) не должны системно обделяться или перевыполняться в рекомендациях. Например, если 40% фильмов в каталоге сняты женщинами-режиссерами, то и в топ-10 рекомендациях тоже примерно 4 из 10 (при прочих равных), а не 0.
* **Item-side fairness:** объекты из разных категорий (или от разных поставщиков) должны иметь шанс быть рекомендованными пропорционально их качеству, а не быть заниженными из-за трендов или предубеждений модели.

Добиться полной беспристрастности сложно, поскольку данные часто содержат **bias** (например, большинство пользователей может предпочитать один жанр – это не вина алгоритма, но отражение реальности; однако задача алгоритма – не усиливать предубеждения, если они были не обоснованы). Методы обеспечения fairness:

* Добавлять в функцию потерь регуляризаторы или специальные слагаемые, поощряющие fairness. Например, штраф за отклонение доли показов группы от ожидаемой.
* Постобработка результатов: изменять ранжирование, чтобы удовлетворить ограничения (например, тот же принцип «разнообразия источников» – не больше N элементов от одной категории).
* **Диагностика данных:** удалять или обесценивать признаки, которые явно ведут к дискриминации (например, не использовать пол, расу как фичи). Хотя косвенные корреляты все равно могут влиять.

Отмечу, что излишняя корректировка тоже может быть спорной, особенно если приводит к меньшей релевантности. Необходим баланс между accuracy и fairness – это часть этических решений компании.

**Конфиденциальность и приватность данных.** Рекомендатели опираются на персональные данные, что вызывает **опасения о приватности**. Пользователи часто не до конца понимают, какие объемы их действий собираются и анализируются. Кейс Netflix Prize, когда по анонимизированным данным рейтингов вычислили личности некоторых пользователей, показал, что даже без имен есть риск deanonymization. Современные подходы:

* **Минимизация данных:** собирать только то, что действительно нужно для модели. Например, если геолокация мало влияет на рекомендации книг, не нужно её сохранять.
* **Анонимизация и агрегирование:** отвязывать явные идентификаторы (именовать пользователей не по email, а по случайным ID), и агрегировать логи (хранить “пользователи типа X сделали Y” вместо детализации по человеку).
* **Differential Privacy:** при публикации данных или предоставлении API стараться добавить шум к статистикам. Например, если внешний аналитический сервис запрашивает «сколько раз фильм A был рекомендован пользователям из города B», система может добавить небольшой шум в ответ, чтобы исключить возможность точно определить индивидуальные действия.
* **Федеративное обучение:** модель обучается прямо на устройствах пользователей. Компания, вместо сырых данных, собирает только **градиенты** или обновленные веса модели, которые являются обобщением многих данных. Так, Google клавиатура учит языковую модель предсказания слов на телефоне и сливает только обновленные веса, не отправляя сами личные сообщения на сервер. В теории можно представить и рекомендатель, где модель обновляется на стороне клиента (например, на Smart TV) и отправляет улучшенные веса – центральный сервис объединяет их (алгоритм FedAvg). Это активно исследуется, хотя не столь тривиально для масштабных рекоммендеров.

Также важна **прозрачность для пользователя**: многие сервисы сейчас дают опцию скачать свои данные, узнать, что о тебе «знает» система. Пользователь может увидеть историю просмотров, лайков – это минимум. А например, Spotify годово делает отчеты (Wrapped), где по сути раскрывает, какие данные о вкусах собраны.

Приватность тесно связана с доверием: если система рекомендует что-то слишком личное (например, человек читал о болезни, а ему начинают рекомендовать лекарство), это может вызвать дискомфорт. Тут переплетается и приватность, и этика – такие случаи должны фильтроваться правилами (обычно на уровне бизнеса говорят «не рекомендовать чувствительный контент даже если алгоритм считает нужным»).

**Объяснимость рекомендаций (Explainability).** Почему мне рекомендуют этот фильм? Пользователи нередко задаются таким вопросом. Объяснимость – способность системы предоставлять понятное обоснование своих рекомендаций. Это важно для:

* **Доверия:** если пользователь понимает причину, он более склонен принять рекомендацию. Например: «Вам понравилась книга *Дюна*, поэтому может заинтересовать *Нейромант* (тоже научная фантастика)».
* **Обучение пользователя:** объяснение может указать на свойство контента («с этим актёром», «в этом же жанре»), и человек прикинет, согласен он с логикой или нет.
* **Отладки и контроля:** для разработчиков объяснимость = прозрачность модели, возможность увидеть, не использует ли она какие-то нежелательные корреляции.

В коллаборативных методах сложнее объяснять (латентные факторы не скажешь простым языком), но можно использовать подход «через похожих пользователей»: «Мы порекомендовали этот товар, потому что другие пользователи со схожим вкусом купили его». Это хоть и абстрактно, но понятно. В item-based еще проще: «Похож на те, что вы оценили высоко» – и можно даже перечислить, на какие похож.

Контентные подходы позволяют очень конкретные объяснения: «Этот фильм рекомендован, потому что в нем играет Том Хэнкс, а вы смотрели несколько фильмов с этим актером». Или визуальные рекомендации в одежде: «Посмотрите, это платье того же фасона, что и те, что вы лайкали».

Объяснения могут быть:

* **На основе признаков:** явно указывают признак (жанр, актер, категория товара).
* **На основе примеров:** показывают, от какого просмотренного объекта “протянулась” рекомендация (e.g. «Потому что вы купили *X*»).
* **Сгенерированные текстом:** есть исследования, где генерируют небольшой текст объяснения, иногда привлекая шаблоны или даже нейросети (LLM могут суммировать причины на естественном языке – новый тренд).
* **Визуализации:** напр., в музыке можно показать “word cloud” жанров что вам нравится, и выделить, что новая песня относится к одному из них.

Стоит отметить, что слишком точное объяснение может раскрыть что-то приватное («мы знаем, что вы беременны, поэтому…» – случай с Target, где по покупкам алгоритмы маркетинга определили беременность). Поэтому объяснения тоже должны быть **этичными** и продуманными.

Наконец, иногда законодательство требует объяснимости: например, в ЕС есть положение о праве на(продолжение) объяснение алгоритмических решений – это стимулирует компании делать рекомендации более прозрачными. Итог: современные рекоммендеры должны быть **интерпретируемыми и ответственными**: предоставлять пользователю понятную информацию и соблюдать его права (включая возможность отказаться от персонализации).

## Современные тренды в рекомендациях

Область рекомендательных систем активно развивается. Вот несколько заметных трендов последних лет:

**Self-Supervised Learning (самосупервизированное обучение).** Столкнувшись с проблемой разреженных данных и отсутствия явных меток, исследователи обратились к методам самонаблюдения. Идея – извлекать сигнал для обучения прямо из структуры данных, *без ручной разметки*. В рекомендациях SSL часто реализуется через **контрастивное обучение**: генерируются две «выгоды» (views) данных для того же пользователя (например, разделить его историю на две части или добавить шум/маскировку), модель пытается предсказать, что эти две выгрузки принадлежат одному пользователю, отличая от выгрузок других пользователей. Таким образом, она учится создавать устойчивые эмбеддинги, близкие для разных подмножеств предпочтений того же человека и далекие для разных людей. Это улучшает представление пользователей и объектов, особенно когда явных данных мало. Self-supervised подходы доказали эффективность: например, улучшение точности факторизационных моделей, добавление контрастивного регуляризатора к графовым рекомендациям (модель SGL – Self-supervised GNN for rec). Также используются **masking-подходы** наподобие BERT: модель обучается восстанавливать пропущенный элемент последовательности предпочтений на основе окружающего (как BERT восстанавливает пропущенное слово). Такие методы позволяют задействовать всю массу неаннотированных логов (что смотрел, в каком порядке) в качестве обучения. *Преимущество:* лучшее обобщение при недостатке данных и более богатые эмбеддинги. *Пример:* недавний обзор отмечает, что SSL позволяет рекоммендерам делать точные прогнозы даже при сильной разреженности данных, извлекая скрытые структуры из неизметкленных взаимодействий.

**Внедрение больших языковых моделей (LLM) в рекомендации.** В 2022–2023 произошел бум больших языковых моделей (GPT-3, GPT-4, etc.), и возник вопрос: можно ли использовать их силу в рекомендательных системах? Несколько направлений интеграции:

* **Разбор и генерация контента:** LLM отлично понимают текст. Они могут суммировать отзывы, извлекать из описаний товаров важные фичи, либо даже генерировать описания новых продуктов. Это помогает обогатить профили объектов и сделать контентную часть рекомендаций точнее. Например, модель может проанализировать отзывы на фильм и понять тональность или скрытые тематики – эти данные включаются в модель ранжирования.
* **LLM как рекомендатель:** первые исследования пытаются *представить задачу рекомендации как задачу языкового моделирования*. Например, проект CALRec от Google кодирует историю пользователя в текстовую подсказку (prompt): берет названия последних просмотренных товаров, категорий, формирует фразу типа «User history: ... Предложи следующий товар:». Затем большой языковая модель (обученная дополнительно) дописывает, что бы пользователь купил. Такой подход позволяет использовать мощь предобученных LLM, которые обладают знаниями и умеют делать некоторые выводы. Результаты пока смешанные: LLM хорошо понимают связь по атрибутам, но без специального обучения могут халлуцинировать или игнорировать некоторые предпочтения. Тем не менее, Google доложил, что их прототип (на основе PaLM-2) превзошел классические модели вроде SASRec на датасете Amazon.
* **LLM для объяснений:** как отмечалось, генерация объяснений – идеально подходит для языковых моделей. Они могут брать причины (например, пересечение по жанрам) и превращать в гладкий текст. Это повышает удовлетворенность: пользователь получает рекомендацию + человеческое объяснение, сгенерированное ИИ.
* **LLM-Agents и диалоговые системы:** появляются концепции, когда агент с LLM общается с пользователем, уточняя предпочтения и давая рекомендации в форме чата. Например, система-ассистент может спросить: «Какой жанр настроены посмотреть?» – и, понимая ответ, сузить подборку.

LLM обладают **сильными языковыми знаниями, способностью к обобщениям и рассуждению**, чего не хватает узкоспециализированным рекомендательным моделям. С другой стороны, LLM очень велики (сотни миллиардов параметров), их трудно и дорого обучать на специфичных данных каждого сервиса. Вероятно, решения будут гибридными: LLM встраиваются как компонент для контента или cold-start, а основная тяжелая математика персонализации остается за специализированными моделями. Тем не менее, уже говорят о появлении **RecGPT** – моделей, которые объединят возможности GPT с задачами рекомендаций.

**Multi-Objective Optimization и Multi-Stakeholder RS.** Как отмечалось ранее, современные платформы оптимизируют не единственную цель. Точность рекомендаций – важно, но может вступать в конфликт с другими целями: разнообразие, справедливость, монетизация, удовлетворенность. Потому растет интерес к методам, позволяющим **учитывать сразу несколько метрик** при обучении модели. Несколько подходов:

* *Взвешивание целей в функции потерь:* простой вариант – посчитать итоговый лосс как `Loss = w1*Loss_accuracy + w2*Loss_diversity + w3*Loss_fairness`. Тогда обучение пытается одновременно минимизировать взвешенную сумму. Подбор весов становится задачей (ее решают перебором или даже применяют верхнеуровневую оптимизацию).
* *Многозадачное обучение:* строится архитектура с несколькими «головами» нейросети – например, одна голова предсказывает рейтинг, другая – вероятность, что пользователь продолжит сессию, третья – вероятность покупки. Общие слои внизу позволяют модели разделять знания, а выходы на каждую задачу специализированы. Это особенно полезно, когда одна задача данных мало, а другая много – совместное обучение улучшит первую.
* *Парето-оптимизация:* вместо скаляризации целей, некоторые исследования генерируют набор решений, лежащих на Парето-фронте (когда нельзя улучшить одну метрику без ухудшения другой), а затем выбирают компромиссное решение. Это вычислительно тяжелее, но дает представление о trade-off.
* *Констейнты (ограничения):* например, оптимизируем основную метрику (CTR), но под ограничением, что diversity ≥ X и fairness-баланс ≤ Y. Тогда задача превращается в оптимизацию с ограничениями – решают приближенно, накладывая штрафы за нарушение ограничений.

В реальном времени multi-objective подход может проявляться через *ре-ранжирование*: взять список, оптимизированный по главной метрике, и перестроить его, чтобы удовлетворить вторичным критериям (например, максимально увеличить разнообразие без сильной потери precision). Такой модуль может использовать алгоритмы типа жадного включения или даже простой If-Then правил (не ставить больше 2 предметов одной категории подряд).

Отдельно стоит упомянуть **multi-stakeholder** рекомендации: когда система учитывает интересы разных сторон. Например, маркетплейс соединяет покупателей и продавцов – нужно угодить и тем, и другим. Удержание покупателей требует релевантности, а продавцы хотят равномерного показа товаров. Система может внедрять механизмы, гарантирующие, что ни один поставщик не монополизирует выдачу (это часть fairness).

Пример *multi-objective* конфликта: сервис потоковой музыки. Цель 1 – удержать пользователя как можно дольше (ставить то, что он точно будет слушать). Цель 2 – продвигать новые песни и исполнителей (чтобы каталог развивался). Чисто оптимизируя первое, система никогда не поставит совсем новую песню, боясь, что слушатель переключит. С учетом второго – иногда рискнет. Баланс подбирается экспериментально и с помощью описанных методов. В исследованиях отмечено, что во многих e-commerce системах есть trade-off между краткосрочными кликами и долгосрочной лояльностью, и грамотные рекомендатели стараются найти золотую середину.

**Cross-Domain и cross-platform рекомендации.** Пользователи взаимодействуют с разными системами, и возникает идея: знания о предпочтениях в одной области использовать в другой. **Cross-domain recommendation** – это перенос или совместное обучение рекомендаций на нескольких доменах. Например:

* Музыкальный сервис может рекомендовать концерты (связь музыка–ивенты).
* Онлайн-магазин может объединять историю покупок в разных категориях: книги и электроника – чтобы по книгам предлагать электронику (если, допустим, книги по фото – предложить камеру).
* Если компания владеет несколькими платформами (видео-сервис и новостной портал), она может обучить общую модель, понимающую вкусы во всех сферах, и улучшить cold-start там, где данных меньше, за счет богатого профиля из другого домена.

Основной вызов – данные из разных доменов **разнородны**: рейтинги фильмов не напрямую укажут, какие новости человек читает. Но есть скрытые связи: например, интерес к спортивным фильмам может коррелировать с чтением спортивных новостей. Технически, часто используют transfer learning: обучают модель на одном домене и дообучают на другом, или привязывают эмбеддинги пользователя в двух системах через некий общий вектор. Иногда строят обобщенное представление *«интересы пользователя»*, куда входят признаки и того, и другого, и обучают единую модель, выдающую рекомендации в обоих доменах.

Cross-domain особенно полезен для **новых сервисов**: когда запускается новый продукт, у компании уже есть данные о пользователях из старых – можно сделать стартовую персонализацию, избежав эффекта нулевого портала. Например, новый стриминговый сервис от условного Amazon сразу может использовать данные Amazon.com для рекомендаций фильмов (зная, что пользователь покупал ранее, какие книги читал – примерно понять жанровые предпочтения).

Еще аспект – **Cross-lingual RS**: рекомендации контента на другом языке, основываясь на оригинальном. Например, рекомендуем иностранные фильмы, которые похожи на любимые фильмы пользователя на родном языке – преодолевая языковой барьер через перевод описаний и факторизацию в общем пространстве.

**Генеративные подходы.** Помимо использования генертивных моделей (как LLM) для текста, существует линия работ, где сами рекомендации формируются через *генерацию данных*:

* **GAN (Generative Adversarial Networks) для рекомендаций:** применяются для улучшения обучения моделей. Пример – IRGAN (2017): генератор предлагает кандидатов объектов, а дискриминатор учится отличать, что пользователь действительно выбрал, а что предложил генератор. В процессе генератор учится генерировать «правдоподобные» предпочтения, тем самым помогая модели лучше понимать распределение интересов. GAN также использовались для *data augmentation* – генератор может создавать искусственные оценки или фидбек для редких событий, сглаживая проблему разреженности. Исследования показывают, что GAN-механизмы помогают бороться с шумом в данных и атаками (например, если есть накрутка рейтингов, GAN-дискриминатор может научиться ее отфильтровывать). Однако GAN обучать сложно, и в продакшене они редки – скорее как исследовательский инструмент.
* **Variational Autoencoders**: уже упоминались – VAE можно считать генертивной моделью, т.к. он учит распределение латентных факторов. Например, Mult-VAE генерирует распределение вероятностей, какие фильмы пользователь бы посмотрел, и показал отличные результаты на топ-N рекомендациях, благодаря тому, что учитывает неопределенность предпочтений. Генеративность VAE также позволяет семплировать разные рекомендации с некоторой случайностью, не показывая каждый раз один и тот же топ – что полезно для разнообразия.
* **Рекомендации как генерация последовательностей:** в музыке или видео можно рассматривать рекомендатель как генератор последовательности треков. Некоторые работы используют Seq2Seq модели (генераторы) для составления плейлиста, оптимизируя условно «драматургию» – например, модель генерирует плейлист из 10 песен, где сначала бодрые, потом медленные (учитывая пожелание пользователя «сделай мне расслабляющий микс»). Такие задачи близки к Sequence Generation в NLP.
* **Диалоговые генеративные рекомендатели:** на стыке с LLM – система сгенерирует не только рекомендацию, но и фразы: «Похоже, вам может понравиться новый альбом X, хотите послушать?» – то есть, генерирует само *действие рекомендации* в человеческом виде.

**Пример генеративного подхода:** сервис новостей может иметь модель, которая генерирует заголовки статей для рассылки пользователю, персонализируя их. Это уже ближе к персонифицированному маркетингу, но граница с рекомендациями размывается.

Наконец, современные исследования смотрят на **causal inference** (причинно-следственные эффекты) в рекомендательных системах – пытаются отделить влияние самой системы от истинных предпочтений. Это важно: если система всегда рекомендовала поп-музыку, пользователь мог просто не слышать других жанров, и его наблюдаемое поведение – не отражение полного интереса, а *результат* работы предыдущего алгоритма. Методы, учитывающие каузальность, пытаются исправить такой *selection bias*.

В целом, тренды указывают на сближение рекомендательных систем с **общим ИИ**: они становятся умнее, универсальнее (способными учитывать текст, изображения, знания), и одновременно – контролируемее, с возможностью оптимизировать под множество критериев. Это делает разработку таких систем еще более комплексной задачей, требующей междисциплинарного подхода (ML, UX, этика, бизнес).

## Применение рекомендательных систем в индустрии

Рассмотрим, как различные отрасли используют рекомендации и какой эффект это даёт:

* **E-commerce (электронная торговля):** Интернет-магазины и маркетплейсы широко используют рекомендации товаров. На витрине пользователя персональный блок «Вам может понравиться» повышает конверсию: по данным Amazon, около **35% выручки генерируется благодаря системе рекомендаций**. Amazon одним из первых внедрил масштабный рекомендательный движок, используя item-to-item коллаборативную фильтрацию для мгновенного показа сопутствующих товаров. Типичные кейсы: *«Клиенты, купившие X, также покупают Y»*, *«Похожие товары»*, *«Вместе с этим часто смотрят…»*. Рекомендации в e-commerce улучшают **cross-sell** (продажу сопутствующих товаров) и **up-sell** (более дорогих товаров). Также на маркетплейсах алгоритмы решают проблему выбора среди огромного ассортимента – персонализация помогает сузить каталог до релевантных позиций, экономя время пользователя. Практически все крупные площадки (Alibaba, eBay, Ozon, Wildberries) имеют свои рекомендательные системы. Благодаря им пользователи находят больше подходящих товаров, что увеличивает удовлетворенность и продажи. Например, персональные рекомендации товаров в среднем повышают конверсию на 5-15%, а средний чек – за счет обнаружения товаров, о которых пользователь не знал.

* **Стриминговые сервисы (видео/кино):** Netflix, YouTube, Hulu, HBO Max – все они критически зависят от рекомендателей, чтобы удерживать внимание зрителя. **Netflix** прославился своим алгоритмом Cinematch (побудившим конкурс Netflix Prize), а сегодня сообщает, что *до 80% просмотренного контента приходится на персональные рекомендации*. Фактически, «все на Netflix – это рекомендация»: от порядка рядов на главном экране до подборки внутри жанров. Рекомендатель Netflix анализирует историю просмотров, оценки, даже поведение схожих профилей, и формирует уникальную витрину фильмов/сериалов. Это приносит коммерческий эффект: пользователи меньше уходят, больше продлевают подписку – по оценкам, алгоритмы сохраняют компании порядка \$1 млрд в год, предотвращая отток аудитории. **YouTube** – один из крупнейших в мире рекомендательных систем: «домашняя» лента и боковые «up next» подобраны персонально. YouTube утверждает, что рекомендации помогают *более чем миллиарду пользователей находить интересное в гигантском корпусе видео*, и без них большинство бы просто терялось в выборe. Алгоритм YouTube (описанный в известной статье 2016 г.) сочетает глубокое обучение и огромные данные – каждый день он обрабатывает миллиарды событий, оптимизируя время просмотра. Видеосервисы благодаря рекомендациям достигают эффекта «залипания»: авто-плей следующего подходящего видео удерживает зрителей, увеличивая общее watch time. **TikTok** – еще более свежий пример: феноменальный рост TikTok во многом приписывают его суперэффективному рекомендательному алгоритму ленты **For You**, который мгновенно подстраивается под интересы на основе нескольких пролистываний. TikTok показывает, что точные рекомендации могут сделать сервис популярнейшим: короткие видео + умные рекомендации = многомиллиардные часы вовлеченности.

* **Музыкальные сервисы:** Spotify, Apple Music, YouTube Music и др. В музыке рекомендации решают задачу знакомства с новым контентом и удержания подписчиков. **Spotify** знаменит плейлистом *Discover Weekly* – каждую неделю для каждого пользователя генерируется подборка новых песен, которые ему могут понравиться. Эта функция стала настолько популярной, что за первые 10 недель было прослушано **более 1 миллиарда треков Discover Weekly**, а сегодня миллионы пользователей начинают свою неделю с персонального плейлиста. Кроме этого, Spotify имеет *Daily Mixes, Release Radar* – все автоматически сгенерировано под вкусы. Алгоритмы учитывают и коллаборативные сигналы (похожие пользователи), и анализ контента (спектрограммы аудио, текст песен). Для стриминга музыка – основной продукт, и если рекомендации промахиваются, пользователь уходит на другой сервис. Успешная рекомендация, напротив, удерживает годами (пользователи ценят, что сервис «понимает их музыкальный вкус»). **Радио-сервисы** (Pandora, Яндекс.Музыка «Радио») – ранний пример content-based рекомендаций, когда по выбранной песне строится последовательное радио из похожих композиций. Сейчас это почти стандартная функция. В целом, в музыкальных стримингах рекоммендеры отвечают за **две цели**: персональный комфорт (любимые треки в миксе) и открытие нового (новые артисты, релизы, жанры, которые могут понравиться). Баланс этих целей – конкурентное преимущество сервиса.

* **Финтех и банки:** Рекомендации в финтехе проявляются, например, как подсказки финансовых продуктов или персональные советы. Банки анализируют транзакции и предлагают услуги: *«У вас остаток средств, откройте депозит»*, *«Ваша поездка за границу – хотите карту для путешествий?»*. Кредитные организации с помощью ML оценивают, кому предложить кредит или повышение лимита, чтобы максимально повысить отклик. Инвестиционные приложения рекомендуют портфели или ценные бумаги на основе интересов и профиля риска пользователя (здесь уже граница с robo-advisors). Особенность финтех-рекомендаций – сильный акцент на **доверии и объяснимости** (клиент должен понимать, почему банк советует именно этот продукт) и на **регуляции** (нельзя показывать предвзято или нарушать compliance). Но потенциал огромен: cross-sell финансовых продуктов через точные рекомендации значительно увеличивает LTV (lifetime value) клиента. Например, сервис персональных финансов может напоминать: «Вы платите много комиссий за ATM, мы рекомендуем подключить пакет Х с бесплатными снятиями» – это ценная персональная подсказка.

* **Социальные сети и контент-платформы:** В соцсетях фактически *весь контент – результат ранжирования рекомендаций*. Лента Facebook, Instagram, Twitter (ныне X) – сортирует посты друзей и пабликов по вероятности заинтересовать пользователя. Алгоритмы учитывают ваши прошлые лайки, с кем вы больше взаимодействуете, какие темы популярны. Например, Facebook years ago сообщал, что без персональной ленты пользователь утонул бы в тысячах ежедневных постов; алгоритм отбирает порядка сотни «самых релевантных». Также **рекомендации друзей** («People You May Know» на Facebook или LinkedIn) – классический пример задачи рекомендации (по графу социальных связей). Для платформ наподобие **Instagram**: вклад рекомендательного движка виден в разделе *Explore* – подбор постов от незнакомых аккаунтов, которые могут вам понравиться (на основе похожих людей, хештегов). А **TikTok**, как упомянуто, превратил всю концепцию соцсети в бесконечный стрим рекомендаций без явных связей – просто видео со всего мира, подобранные под ваш вкус. В **Twitter/X** и **Reddit** тоже ленты формируются с помощью ML, хотя там сильна доля хронологического порядка для тех, кто предпочитает. **Pinterest** применяет рекомендации для показов визуального контента («пины, которые вам понравятся») – используя графовые модели (PinSage). В целом, соцсети стремятся максимизировать вовлеченность (время, клики, шеринг) через рекомендации. С этической стороны, это приводит к дискуссиям о пузырях и влиянии на общественное мнение, о чем мы говорили ранее.

* **Онлайн-образование:** Платформы обучения (Coursera, Udemy, Stepik) используют рекомендации для курсов, уроков, материалов. Кейс: *«Вам понравился курс по Python, возможно, стоит пройти курс по алгоритмам».* Такие системы повышают удержание студентов, помогая выбрать следующий шаг в обучении. Кроме того, внутри курсов могут рекомендоваться доп. материалы: статьи, книги, если студент испытывает сложности – подсказать главу учебника. **Персонализация траектории обучения** – активная область: adaptive learning системы подстраиваются под ученика, рекомендуя больше практики по темам, где он слабее, и пропуская уже усвоенные темы. Здесь рекомендации выступают как виртуальный наставник. Например, Duolingo (языковое обучение) рекомендует повторить слова, которые именно вы часто ошибаете – по сути, тоже рекомендация, основанная на профиле знаний. В корпоративном обучении рекомендации помогают сотрудникам найти релевантные курсы для повышения квалификации, что ценно для HR-развития.

* **Рекрутинг и поиски работы:** На сайтах вакансий и профессиональных соцсетях (LinkedIn, HeadHunter) стоят двусторонние рекомендательные системы: соискателям показывают подходящие вакансии, а рекрутерам – подходящих кандидатов. LinkedIn, например, имеет функцию *«Jobs You Might Be Interested In»*, которая учитывает ваш профиль, навыки, историю просмотров вакансий. Также *поиск талантов* для HR: алгоритмы ранжируют миллионы профилей, подсказывая, кого стоит позвать на открытую позицию (учитывая опыт, рекомендации, схожесть с успешными сотрудниками компании и т.д.). Хорошая рекомендательная система в рекрутинге экономит огромное время на ручной поиск и повышает шансы успешного найма. Сложность – учитывать очень много факторов (навыки, география, желаемая зарплата, активность кандидата). В этой сфере также важна **справедливость**: чтобы алгоритм не дискриминировал кандидатов (были случаи, когда ИИ по найму оказался сексистским из-за данных). Поэтому внедряют контролируемые алгоритмы или гибрид с участием человека.

* **Путешествия и отели:** Туристические сервисы (Booking, Airbnb, Expedia, TripAdvisor) рекомендуют: отели, направления, билеты, развлечения. Например, Booking.com персонализирует результаты поиска отелей – два разных пользователя могут увидеть разные отели в топе по одному городу, если у них разные паттерны (одному – дешевле хостелы, другому – бизнес-отели). Airbnb рекомендует варианты жилья *«похожие на просмотренные»*, а также *Experience*-мероприятия на основе вашего профиля. Сезонность и локальный контекст тоже учитываются: осенью могут рекомендоваться тёплые страны, а зимой – горнолыжные туры. TripAdvisor после того, как вы посетили страницу достопримечательности, покажет *«другие туристы также посмотрели…»*. Тут сочетание контентных (похожие места) и коллаборативных (другие туристы с похожими интересами) методов. Рекомендации в travel повышают вероятность бронирования и помогают пользователю планировать лучше. Важен и real-time: мобильные приложения могут на месте посоветовать ресторан рядом с отелем, учитывая предпочтения из вашего домашнего города.

* **Онлайн-медиа, новости и статьи:** Новостные агрегаторы (Google News, Яндекс.Дзен, Microsoft News) и сайты СМИ активно применяют рекомендации для персонализированной ленты новостей. Пользователь, интересующийся спортом, будет чаще видеть спортивные новости, а кто в технике – новости IT. Такие платформы наблюдают за тем, что читает человек, сколько времени проводит, и на базе этого регулируют подачу. По заявлениям отрасли, персонализация новостей может увеличить вовлеченность на 20-30%. **Однако,** как обсуждалось, есть риск эффекта пузыря – поэтому многие новостные рекоммендеры вводят долю общего контента (тренды дня, важные мировые новости) вне зависимости от профиля, чтобы расширить кругозор читателя. Статьи и блоги – еще один кейс: например, Medium и VC.ru рекомендуют пользователям статьи на основе ранее прочитанных, чтобы те переходили с одной интересной публикации на другую. **Журналы и контент-платформы** (BuzzFeed, Reddit) тоже используют алгоритмы, чтобы показывать наиболее релевантные посты каждому – у Reddit есть персональная лента “Home” помимо подписок на сабреддиты.

* **Различные специализированные сервисы:** Рекомендательные системы проникли практически везде, где есть выбор. *Виртуальные магазины приложений* (App Store, Google Play) – рекомендуют приложения («похожие на уже установленные», «для вас» подборки). *Электронные библиотеки и научные сети* – советуют статьи и книги (например, Google Scholar с модулем “Related articles” или ResearchGate – «люди с похожими интересами читали...»). *Онлайн-мероприятия* – платформа Meetup предлагает группы по интересам, Netflix Events рекомендует фестивали фильмов на основе вашего вкуса. *Услуги питания* – Delivery Club/Яндекс.Еда могут рекомендовать новые рестораны, основываясь на предыдущих заказах. *Автомобильные сервисы* – условный recommender может советовать услуги по обслуживанию авто исходя из истории владения (если вы два года не меняли шины – напомнит и посоветует магазин рядом). Список можно продолжать.

**Итоги по индустрии:** рекомендательные системы стали неотъемлемой частью цифрового опыта. Они повышают *удобство* для пользователя (меньше искать – больше находить) и *ключевые метрики успеха* для бизнеса: вовлеченность, конверсию, выручку, лояльность. Огромные проценты контента потребляются благодаря рекомендациям – **75–80% просмотренного на Netflix, 70% часов на YouTube, 35% покупок на Amazon** – эти цифры демонстрируют влияние. При правильном применении, рекоммендеры дают *win-win*: пользователь доволен, что ему всегда есть что посмотреть/купить, а платформа растёт. Однако, мы видели, что с этим приходят и ответственности – избегать негативных эффектов и обеспечивать прозрачность.

**Пример суммарного эффекта:** Spotify отмечает, что персонализация не только удерживает существующих пользователей, но и привлекает новых – люди рассказывают о точности Discover Weekly, фактически реклама «сарафанным радио». В Netflix персонализация контента позволила успешно продвигать собственные сериалы именно той аудитории, которой они зайдут, делая хиты из нишевых проектов. В e-commerce, благодаря рекомендациям, пользователи тратят больше – по оценкам McKinsey, внедрение рекомендательных движков в ритейле может повысить выручку на 10-15%.

Резюмируя: рекомендации – одна из самых **успешных реализаций ИИ** в индустрии. Они объединяют алгоритмы машинного обучения, большие данные и психологию пользователя. Для начинающих специалистов важно понимать, что за удобными секциями «вам рекомендуется» стоит богатый стек технологий и нюансов – от алгоритмов факторизации до этических соображений. И эта сфера продолжает развиваться, становясь всё более интеллектуальной и ориентированной на человека.

### **Заключение:**

Рекомендательные системы прошли путь от простых списков популярных товаров до сложных мультифакторных ИИ-моделей, пронизывающих все цифровые сервисы. Знание основ (коллаборативные и контентные методы), умение применять современные модели (матричная факторизация, нейросети, графовые алгоритмы), понимание инфраструктуры (оффлайн обучение, онлайн-раскатка, A/B тесты) и внимание к этическим аспектам – вот составляющие успешной работы с рекомендациями. Вооружившись этой методичкой, начинающий инженер сможет уверенно сделать первые шаги в создании рекомендательных систем и понять, как улучшать их качество. А примеры из индустрии послужат ориентиром, как применить эти знания на практике и каких результатов можно добиться.

**Источники и литература:** данная методичка опиралась на широкий спектр научных и прикладных материалов – от классических обзоров (Ricci *Recommender Systems Handbook*) до последних статей 2023 года по SSL и LLM в рекомендациях, а также на кейсы Amazon, Netflix, Spotify и других компаний. Рекомендуем для углубления: отчеты Netflix TechBlog о персонализации, статьи в *ACM RecSys* конференциях, блоги (Google AI Blog, Medium) с разбором алгоритмов, и практические руководства (например, курсы на Coursera, книга «Практические рекомендательные системы»). Пусть ваши рекомендатели будут точными, разнообразными и этичными!
